{"version":3,"sources":["../src/datumRangeFinder.js","../src/datumLoader.js","../src/jsonClientSupport.js","../src/datumSourceFinder.js","../src/multiLoader.js"],"names":["extractReportableInterval","results","result","repInterval","i","length","undefined","data","endDate","endDateMillis","startDateMillis","startDate","log","debug","this","_helpers","nodeId","sourceIds","join","datumExtractor","json","success","Array","isArray","pageSizeExtractor","returnedResultCount","startingOffset","totalResults","offsetExtractor","page","max","JsonClientSupport","authBuilder","_classCallCheck","jsonClient","value","_this","Promise","resolve","reject","load","error","callback","Error","DatumRangeFinder","urlHelpers","_possibleConstructorReturn","_getPrototypeOf","call","Object","defineProperties","_assertThisInitialized","version","NodeDatumUrlHelper","q","queue","client","auth","_iteratorNormalCompletion","_didIteratorError","_iteratorError","_step","_loop","url","reportableIntervalUrl","req","on","request","signingKeyValid","reset","snDate","setRequestHeader","HttpHeaders","X_SN_DATE","requestDateHeaderValue","AUTHORIZATION","buildWithSavedKey","defer","get","_iterator","Symbol","iterator","next","done","err","return","awaitAll","intervalObj","sDate","Date","eDate","DatumSourceFinder","DatumFilter","datumFilter","addRequest","key","requestKeys","push","urlHelper","filter","nodeIds","metadataFilter","availableSourcesUrl","_iteratorNormalCompletion4","_didIteratorError4","_iteratorError4","_step4","_iterator4","oneFilter","len","_iteratorNormalCompletion2","_didIteratorError2","_iteratorError2","_step2","_iterator2","pair","indexOf","sourceId","_iteratorNormalCompletion3","_didIteratorError3","_iteratorError3","_step3","_iterator3","DatumLoader","publicQuery","withoutTotalResultsCount","_pageSize","_includeTotalResultsCount","_finishedCallback","_urlParameters","_incrementalMode","_readingsMode","_proxyUrl","_concurrency","_queue","_state","_results","isNaN","Number","_typeof","Infinity","loadData","Pagination","args","apply","_this2","pagination","queryFilter","offset","datumReadingUrl","DatumReadingTypes","Difference","listDatumUrl","queryParams","urlQuery","urlQueryEncode","reqUrl","replace","dataArray","incMode","nextOffset","handleResults","concat","pOffset","withOffset","allResults","findIndex","el","map","qJson","forEach","resultArray","MultiLoader","loaders","_loaders","n","loader","bind"],"mappings":"y/CAgJA,SAASA,EAA0BC,GAClC,IAAIC,EAEHC,EADAC,EAAI,EAEL,IAAKA,EAAI,EAAGA,EAAIH,EAAQI,OAAQD,GAAK,OAEXE,KADzBH,EAAcF,EAAQG,IACNG,WAAmDD,IAA7BH,EAAYI,KAAKC,SAQvDL,EAAcA,EAAYI,UACXD,IAAXJ,EACHA,EAASC,GAILA,EAAYM,cAAgBP,EAAOO,gBACtCP,EAAOO,cAAgBN,EAAYM,cACnCP,EAAOM,QAAUL,EAAYK,SAE1BL,EAAYO,gBAAkBR,EAAOQ,kBACxCR,EAAOQ,gBAAkBP,EAAYO,gBACrCR,EAAOS,UAAYR,EAAYQ,aAnBhCC,EAAAA,OAAIC,MACH,sCACAC,KAAKC,SAASX,GAAGY,OACjBF,KAAKC,SAASX,GAAGa,UAAUC,KAAK,MAoBnC,OAAOhB,EC8TR,SAASiB,EAAeC,GACvB,GACEA,IACgB,IAAjBA,EAAKC,cACSf,IAAdc,EAAKb,OACgC,IAArCe,MAAMC,QAAQH,EAAKb,KAAKN,SAIzB,OAAOmB,EAAKb,KAAKN,QAUlB,SAASuB,EAAkBJ,GAC1B,IAAMA,IAAQA,EAAKb,KAClB,OAAO,EAER,IAAMA,EAAOa,EAAKb,KAClB,OAAOA,EAAKkB,oBAAsBlB,EAAKmB,eAAiBnB,EAAKoB,aAC1DpB,EAAKkB,oBACL,EAgBJ,SAASG,EAAgBR,EAAMS,GAC9B,IAAMT,IAAQA,EAAKb,KAClB,OAAO,EAER,IAAMA,EAAOa,EAAKb,KAClB,OAAIsB,GAAQA,EAAKC,IAETvB,EAAKkB,oBAAsBI,EAAKC,IAAM,EAAIvB,EAAKmB,eAAiBG,EAAKC,IAEtEvB,EAAKkB,oBAAsBlB,EAAKmB,eAAiBnB,EAAKoB,aAC1DpB,EAAKkB,oBAAsBlB,EAAKmB,eAChC,MClhBEK,aAOL,SAAAA,EAAYC,GAAaC,EAAAnB,KAAAiB,GAMxBjB,KAAKkB,YAAcA,EAMnBlB,KAAKoB,WAAad,EAAAA,8CAYZe,GACN,OAAKA,GACgB,mBAAVA,IACVrB,KAAKoB,WAAaC,GAEZrB,MAJYA,KAAKoB,2CAcjB,IAAAE,EAAAtB,KACP,OAAO,IAAIuB,QAAQ,SAACC,EAASC,GAC5BH,EAAKI,KAAK,SAACC,EAAOxC,GACbwC,EACHF,EAAOE,GAEPH,EAAQrC,oCAePyC,GACJA,EAAS,IAAIC,MAAM,8DFlBfC,cASL,SAAAA,EAAYC,EAAYb,GAAa,IAAAI,EAAA,OAAAH,EAAAnB,KAAA8B,GACpCR,EAAAU,EAAAhC,KAAAiC,EAAAH,GAAAI,KAAAlC,KAAMkB,IACNiB,OAAOC,iBAAPC,EAAAf,IAQCgB,SAAWjB,MAAO,WAOnBC,EAAKrB,SAAWO,MAAMC,QAAQsB,GAC3BA,EACAA,GACCA,IACA,IAAIQ,EAAAA,oBArB4BjB,aATPL,mCAuCzBW,GACJ,IAAMY,EAAIC,EAAAA,QACJrB,EAAapB,KAAK0C,SAClBC,EAAO3C,KAAKkB,YAHJ0B,GAAA,EAAAC,GAAA,EAAAC,OAAAtD,EAAA,IAId,IAAA,IAAAuD,EAJcC,EAAA,WAAA,IAKPC,EALOF,EAAA1B,MAKS6B,wBAChBC,EAAM/B,EAAW6B,GAAKG,GAAG,aAAc,SAAAC,GACxCV,GAAQA,EAAKW,kBAChBX,EAAKY,QACHC,QAAO,GACPP,IAAIA,GAAK,GACXI,EAAQI,iBAAiBC,EAAAA,YAAYC,UAAWhB,EAAKiB,wBACrDP,EAAQI,iBAAiBC,EAAAA,YAAYG,cAAelB,EAAKmB,wBAG3DtB,EAAEuB,MAAMZ,EAAIa,IAAK,OAXlBC,EAAwBjE,KAAKC,SAA7BiE,OAAAC,cAAAvB,GAAAG,EAAAkB,EAAAG,QAAAC,MAAAzB,GAAA,EAAuCI,IAJzB,MAAAsB,GAAAzB,GAAA,EAAAC,EAAAwB,EAAA,QAAA,IAAA1B,GAAA,MAAAqB,EAAAM,QAAAN,EAAAM,SAAA,QAAA,GAAA1B,EAAA,MAAAC,GAiBdN,EAAEgC,SAAS,SAAC7C,EAAOxC,GAClB,GAAIwC,EAKH,OAJA7B,EAAAA,OAAI6B,MAAM,4CAA6CA,QAC/B,mBAAbC,GACVA,EAASD,IAIX,IAAI8C,EAAcvF,EAA0BC,QACRK,IAAhCiF,EAAY7E,kBACf6E,EAAYC,MAAQ,IAAIC,KAAKF,EAAY7E,uBAERJ,IAA9BiF,EAAY9E,gBACf8E,EAAYG,MAAQ,IAAID,KAAKF,EAAY9E,gBAGlB,mBAAbiC,GACVA,EAAS,KAAM6C,cG7FbI,cASL,SAAAA,EAAY9C,EAAYb,GAAa,IAAAI,EAAA,OAAAH,EAAAnB,KAAA6E,GACpCvD,EAAAU,EAAAhC,KAAAiC,EAAA4C,GAAA3C,KAAAlC,KAAMkB,IACNiB,OAAOC,iBAAPC,EAAAf,IAQCgB,SAAWjB,MAAO,WAOnBC,EAAKrB,SAAWO,MAAMC,QAAQsB,GAC3BA,EACAA,GACCA,IACA,IAAIQ,EAAAA,oBArB4BjB,aATNL,qCAyCxBI,GACN,OAAKA,GACDA,aAAiByD,EAAAA,cACpB9E,KAAK+E,YAAc1D,GAEbrB,MAJYA,KAAK+E,yCAapBnD,GAMJ,SAASoD,EAAWC,EAAKhC,GACxBiC,EAAYC,KAAKF,GACjB,IAAM9B,EAAM/B,EAAW6B,GAAKG,GAAG,aAAc,SAAAC,GACxCV,GAAQA,EAAKW,kBAChBX,EAAKY,QACHC,QAAO,GACPP,IAAIA,GAAK,GACXI,EAAQI,iBAAiBC,EAAAA,YAAYC,UAAWhB,EAAKiB,wBACrDP,EAAQI,iBAAiBC,EAAAA,YAAYG,cAAelB,EAAKmB,wBAG3DtB,EAAEuB,MAAMZ,EAAIa,IAAK,MAhBlB,IAAMxB,EAAIC,EAAAA,QACJrB,EAAapB,KAAK0C,SAClBC,EAAO3C,KAAKkB,YACZgE,KAJQtC,GAAA,EAAAC,GAAA,EAAAC,OAAAtD,EAAA,IAmBd,IAAA,IAAAuD,EAAAkB,EAAwBjE,KAAKC,SAA7BiE,OAAAC,cAAAvB,GAAAG,EAAAkB,EAAAG,QAAAC,MAAAzB,GAAA,EAAuC,CAAA,IAA5BwC,EAA4BrC,EAAA1B,MAChCgE,EAAS,IAAIP,EAAAA,YAAY9E,KAAK+E,aAEpC,GADAM,EAAOC,QAAUF,EAAUE,QACvBD,EAAOE,gBAA4C,IAA1BF,EAAOC,QAAQ/F,OAE3CyF,EACChF,KAAKuF,eAAiB,KAAOF,EAAOnF,OACpCkF,EAAUI,oBAAoBH,QAEzB,CAAA,IAAAI,GAAA,EAAAC,GAAA,EAAAC,OAAAnG,EAAA,IAEN,IAAA,IAAAoG,EAAAC,EAAqBR,EAAOC,QAA5BpB,OAAAC,cAAAsB,GAAAG,EAAAC,EAAAzB,QAAAC,MAAAoB,GAAA,EAAqC,CAAA,IAA1BvF,EAA0B0F,EAAAvE,MAC9ByE,EAAY,IAAIhB,EAAAA,YAAYO,GAClCS,EAAU5F,OAASA,EACnB8E,EAAW9E,EAAQkF,EAAUI,oBAAoBM,KAL5C,MAAAxB,GAAAoB,GAAA,EAAAC,EAAArB,EAAA,QAAA,IAAAmB,GAAA,MAAAI,EAAAtB,QAAAsB,EAAAtB,SAAA,QAAA,GAAAmB,EAAA,MAAAC,MA5BM,MAAArB,GAAAzB,GAAA,EAAAC,EAAAwB,EAAA,QAAA,IAAA1B,GAAA,MAAAqB,EAAAM,QAAAN,EAAAM,SAAA,QAAA,GAAA1B,EAAA,MAAAC,GAsCdN,EAAEgC,SAAS,SAAC7C,EAAOxC,GAClB,GAAIwC,EAKH,OAJA7B,EAAAA,OAAI6B,MAAM,yCAA0CA,QAC5B,mBAAbC,GACVA,EAASD,IAOX,IAAK,IAFCvC,KAEGE,EAAI,EAAGyG,EAAM5G,EAAQI,OAAQD,EAAIyG,EAAKzG,GAAK,EAAG,CACtD,IAAMG,EAAOe,MAAMC,QAAQtB,EAAQG,GAAGG,MAAQN,EAAQG,GAAGG,UAAOD,EAChE,GAAKC,EAAL,CAGA,IAAMwF,EAAMC,EAAY5F,GACxB,GAAY,OAAR2F,EAAc,CAAA,IAAAe,GAAA,EAAAC,GAAA,EAAAC,OAAA1G,EAAA,IAEjB,IAAA,IAAA2G,EAAAC,EAAmB3G,EAAnByE,OAAAC,cAAA6B,GAAAG,EAAAC,EAAAhC,QAAAC,MAAA2B,GAAA,EAAyB,CAAA,IAAdK,EAAcF,EAAA9E,MACpBiE,EAAUlG,EAAOiH,EAAKnG,QACrBoF,IACJA,KACAlG,EAAOiH,EAAKnG,QAAUoF,GAEnBA,EAAQgB,QAAQD,EAAKE,UAAY,GACpCjB,EAAQH,KAAKkB,EAAKE,WATH,MAAAjC,GAAA2B,GAAA,EAAAC,EAAA5B,EAAA,QAAA,IAAA0B,GAAA,MAAAI,EAAA7B,QAAA6B,EAAA7B,SAAA,QAAA,GAAA0B,EAAA,MAAAC,QAYX,CAEN,IAAIZ,EAAUlG,EAAO6F,GACrB,GAAKK,EAEE,CAAA,IAAAkB,GAAA,EAAAC,GAAA,EAAAC,OAAAlH,EAAA,IACN,IAAA,IAAAmH,EAAAC,EAAuBnH,EAAvByE,OAAAC,cAAAqC,GAAAG,EAAAC,EAAAxC,QAAAC,MAAAmC,GAAA,EAA6B,CAAA,IAAlBD,EAAkBI,EAAAtF,MACxBiE,EAAQgB,QAAQC,GAAY,GAC/BjB,EAAQH,KAAKoB,IAHT,MAAAjC,GAAAmC,GAAA,EAAAC,EAAApC,EAAA,QAAA,IAAAkC,GAAA,MAAAI,EAAArC,QAAAqC,EAAArC,SAAA,QAAA,GAAAkC,EAAA,MAAAC,SADNtH,EAAO6F,GAAOxF,IAWO,mBAAbmC,GACVA,EAAS,KAAMxC,cFlIbyH,cAUL,SAAAA,EAAYzB,EAAWC,EAAQnE,GAAa,IAAAI,EAAA,OAAAH,EAAAnB,KAAA6G,GAC3CvF,EAAAU,EAAAhC,KAAAiC,EAAA4E,GAAA3E,KAAAlC,KAAMkB,IACNiB,OAAOC,iBAAPC,EAAAf,IAQCgB,SAAWjB,MAAO,WAInBC,EAAK8D,UAAYA,GAAa,IAAI7C,EAAAA,mBAC7BrB,IACJkE,EAAU0B,aAAc,GAIzBxF,EAAK+D,OACJA,GACA,IAAIP,EAAAA,aACHQ,QAAShE,EAAK8D,UAAUE,QACxByB,0BAA0B,IAO5BzF,EAAK0F,UAAY,IAMjB1F,EAAK2F,2BAA4B,EAMjC3F,EAAK4F,uBAAoB1H,EAMzB8B,EAAK6F,oBAAiB3H,EAQtB8B,EAAK8F,kBAAmB,EAOxB9F,EAAK+F,eAAgB,EAQrB/F,EAAKgG,eAAY9H,EAQjB8B,EAAKiG,aAAe,EAOpBjG,EAAKkG,OAAS,KAMdlG,EAAKmG,OAAS,EAMdnG,EAAKoG,cAAWlI,EAnG2B8B,aAVnBL,0CA8HbI,GACX,YAAc7B,IAAV6B,EACIrB,KAAKuH,eAERI,MAAMtG,IAAUuG,OAAOvG,GAAS,IACpCrB,KAAKuH,aAAeK,OAAOvG,IAErBrB,uCAYCqB,GACR,OAAKA,GAGgB,mBAAVA,IACVrB,KAAKkH,kBAAoB7F,GAEnBrB,MALCA,KAAKkH,qDAeH7F,GACV,OAAKA,GACgB,WAAjBwG,EAAOxG,KACVrB,KAAKmH,eAAiB9F,GAEhBrB,MAJYA,KAAKmH,mDAqBb9F,GACX,YAAc7B,IAAV6B,EAA4BrB,KAAKoH,kBACrCpH,KAAKoH,mBAAqB/F,EACnBrB,6CASOqB,GACd,OAAIsG,MAAMC,OAAOvG,IAAgBrB,KAAKgH,WACtChH,KAAKgH,UAAY3F,EACVrB,uDAaiBqB,GACxB,YAAc7B,IAAV6B,EAA4BrB,KAAKiH,2BACrCjH,KAAKiH,4BAA8B5F,EAC5BrB,uCAeCqB,GACR,YAAc7B,IAAV6B,EAA4BrB,KAAKqH,eACrCrH,KAAKqH,gBAAkBhG,EAChBrB,uCAeCqB,GACR,YAAc7B,IAAV6B,EAA4BrB,KAAKsH,WACrCtH,KAAKsH,UAAYjG,QAAgB7B,EAC1BQ,mCAcH4B,GAUJ,MARwB,mBAAbA,IACV5B,KAAKkH,kBAAoBtF,GAE1B5B,KAAKyH,OAAS,EACVzH,KAAKuH,aAAe,IACvBvH,KAAKwH,OAAS/E,EAAAA,MAAMzC,KAAKuH,eAAiBO,EAAAA,EAAW,KAAO9H,KAAKuH,eAElEvH,KAAK+H,SAAS,IAAIC,EAAAA,WAAWhI,KAAKgH,UAAW,IACtChH,2CAYM2B,EAAO0C,EAAMtD,GAK1B,GAJIsD,IACHrE,KAAKyH,OAAS,GAGXzH,KAAKkH,kBAAmB,CAC3B,IAAIe,GAAQtG,EAAO3B,KAAK0H,UACpB1H,KAAKoH,mBACRa,EAAK9C,KAAKd,GACV4D,EAAK9C,KAAKpE,IAEXf,KAAKkH,kBAAkBgB,MAAMlI,KAAMiI,qCAW5BlH,GAAM,IAAAoH,EAAAnI,KACR2C,EAAO3C,KAAKkB,YACZsB,EAAIxC,KAAKwH,OACXY,EAAarH,aAAgBiH,EAAAA,WAAajH,EAAO,IAAIiH,EAAAA,WACnDK,EAAc,IAAIvD,EAAAA,YAAY9E,KAAKqF,QACzCgD,EAAYtB,0BACV/G,KAAKiH,4BAA6BzE,GAA4B,IAAtB4F,EAAWE,OAErD,IAAIrF,EAAMjD,KAAKqH,cACZrH,KAAKoF,UAAUmD,gBACfF,EACAG,EAAAA,kBAAkBC,gBAClBjJ,OACAA,EACA4I,GAEApI,KAAKoF,UAAUsD,aAAaL,OAAa7I,EAAW4I,GACvD,GAAIpI,KAAKmH,eAAgB,CACxB,IAAIwB,EAAcC,EAAAA,SAASC,eAAe7I,KAAKmH,gBAC3CwB,IACH1F,GAAO,IAAM0F,GAGf,IAAMG,EAAS9I,KAAKsH,UAAYrE,EAAI8F,QAAQ,mBAAoB/I,KAAKsH,WAAarE,EAE5EE,EADanD,KAAK0C,SACDoG,GACrB1F,GAAG,aAAc,SAAAC,GACbV,GAAQA,EAAKW,kBAChBX,EAAKY,QACHC,QAAO,GACPP,IAAIA,GAAK,GACXI,EAAQI,iBAAiBC,EAAAA,YAAYC,UAAWhB,EAAKiB,wBACrDP,EAAQI,iBAAiBC,EAAAA,YAAYG,cAAelB,EAAKmB,wBAG1DV,GAAG,OAAQ,SAAA9C,GACX,IAAI0I,EAAY3I,EAAeC,GAC/B,QAAkBd,IAAdwJ,IACHlJ,EAAAA,OAAIC,MAAM,2BAA4B+I,GACjCtG,GAFN,CAQA,IAAMyG,EAAUd,EAAKf,iBACf8B,EAAapI,EAAgBR,EAAM8H,GACnCvH,EAAeP,GAAQA,EAAKb,KAAOa,EAAKb,KAAKoB,aAAe,KAElE,QAAsBrB,IAAlB2I,EAAKT,UAA0BuB,EAAS,CAI3C,GAHAd,EAAKT,SAAWsB,EAGZZ,EAAWpH,IAAM,EAAG,CACvB,IAAMA,EAAMN,EAAkBJ,GAC1BU,EAAM,IACToH,EAAa,IAAIJ,EAAAA,WAAWhH,EAAKoH,EAAWE,SAG1CW,GACHd,EAAKgB,mBAAc3J,EAAW0J,EAAa,EAAGd,QAEpC5F,IACX2F,EAAKT,SAAWS,EAAKT,SAAS0B,OAAOJ,IAItC,GAAIE,EAAa,GAAM1G,GAAK4F,EAAWE,OAAS,EAC/C,GAAI9F,GACH,GAAI3B,EAAe,EAAG,CAErB,IACC,IAAIwI,EAAUH,EACdG,EAAUxI,EACVwI,GAAWjB,EAAWpH,IAEtBmH,EAAKJ,SAASK,EAAWkB,WAAWD,IAErC7G,EAAEgC,SAAS,SAAC7C,EAAO4H,IAEhB5H,GACD4H,GACAA,EAAWC,UAAU,SAAAC,GAAE,YAAWjK,IAAPiK,KAAqB,IAMhD9H,EAAQ,IAAIE,MACX,6EAGGF,GACJ4H,EACEG,IAAI,SAASC,GACb,OAAOtJ,EAAesJ,SAEtBC,QAAQ,SAAAC,GACR1B,EAAKT,SAAWS,EAAKT,SAAS0B,OAAOS,KAGxC1B,EAAKgB,cAAwB,OAAVxH,EAAiBA,OAAQnC,GAAW,WAIzD2I,EAAKJ,SAASK,EAAWkB,WAAWJ,SAE1BD,GACXd,EAAKgB,mBAAc3J,GAAW,QApE7B2I,EAAKgB,kBAuEP/F,GAAG,QAAS,SAAAzB,GACZ7B,EAAAA,OAAI6B,MAAM,mCAAoCmH,EAAQnH,GACtDwG,EAAKgB,cAAc,IAAItH,MAAJ,6BAAAuH,OAAuCN,EAAvC,MAAAM,OAAkDzH,OAEnEa,GAAK4F,EAAWE,OAAS,EAC5B9F,EAAEuB,MAAMZ,EAAIa,IAAK,MAEjBb,EAAIa,eGpaD8F,aAML,SAAAA,EAAYC,GAAS5I,EAAAnB,KAAA8J,GACpB3H,OAAOC,iBAAiBpC,MAQvBsC,SAAWjB,MAAO,WAOnBrB,KAAKgK,SAAWD,EAMhB/J,KAAKkH,uBAAoB1H,EAMzBQ,KAAKuH,aAAeO,EAAAA,gDAYTzG,GACX,QAAc7B,IAAV6B,EACH,OAAOrB,KAAKuH,aAEb,IAAI0C,EAAIrC,OAAOvG,GAIf,OAHKsG,MAAMtG,IAAU4I,EAAI,IACxBjK,KAAKuH,aAAe0C,GAEdjK,qCAUA,IAAAsB,EAAAtB,KACP,OAAO,IAAIuB,QAAQ,SAACC,EAASC,GAC5BH,EAAKI,KAAK,SAACC,EAAOxC,GACbwC,EACHF,EAAOE,GAEPH,EAAQrC,oCAgBPyC,GAAU,IAAAuG,EAAAnI,KAEU,mBAAb4B,IACV5B,KAAKkH,kBAAoBtF,GAE1B,IAAMY,EAAIC,EAAAA,MAAMzC,KAAKuH,cAUrB,OATAvH,KAAKgK,SAASJ,QAAQ,SAAAM,GAErB1H,EAAEuB,MAAMmG,EAAOxI,KAAKyI,KAAKD,MAE1B1H,EAAEgC,SAAS,SAAC7C,EAAOxC,GACdgJ,EAAKjB,mBACRiB,EAAKjB,kBAAkBhF,KAAKiG,EAAMxG,EAAOxC,KAGpCa,sCAWCqB,GACR,OAAKA,GAGgB,mBAAVA,IACVrB,KAAKkH,kBAAoB7F,GAEnBrB,MALCA,KAAKkH","file":"lib/solarnetwork-datum-loader.min.js.map","sourcesContent":["import { queue } from \"d3-queue\";\nimport { HttpHeaders, Logger as log, NodeDatumUrlHelper } from \"solarnetwork-api-core\";\n\nimport JsonClientSupport from \"./jsonClientSupport\";\n\n/**\n * @typedef {Object} DatumRange\n * @property {string} timeZone the local time zone of the node\n * @property {number} startDateMillis the start of the time range, in milliseconds since the epoch\n * @property {number} endDateMillis the end of the time range, in milliseconds since the epoch\n * @property {Date} sDate the start of the time range\n * @property {Date} eDate the end of the time range\n */\n\n/**\n * The data callback function.\n *\n * @callback DatumRangeFinder~dataCallback\n * @param {Error} [error] an error if a failure occurred\n * @param {DatumRange} data the result data\n */\n\n/**\n * Class to find the available datum date range for a set of node datum URL helpers.\n *\n * This is useful when generating reports or charts for a set of SolarNode datum streams,\n * so the overall start/end dates can be determined before requesting the actual data.\n * It returns an object starting and ending date related properties, for example:\n *\n * ```\n * {\n *   \"timeZone\":        \"Pacific/Auckland\",\n *   \"sDate\":           Date(1248668709972),\n *   \"startDate\":       \"2009-07-27 16:25\",\n *   \"startDateMillis\": 1248668709972,\n *   \"eDate\":           Date(1379824746781),\n *   \"endDate\":         \"2013-09-22 16:39\",\n *   \"endDateMillis\":   1379824746781\n * }\n * ```\n * @extends {JsonClientSupport}\n * @example\n * // the simple case, for just one SolarNode\n * const urlHelper = new NodeDatumUrlHelper();\n * urlHelper.publicQuery = true;\n * urlHelper.nodeId = 123;\n * urlHelper.sourceIds = ['a', 'b'];\n * const range = await new DatumRangeFinder(urlHelper).fetch();\n *\n * @example\n * // more complex case, for multiple SolarNode / source ID combinations\n * const urlHelper2 = new NodeDatumUrlHelper();\n * urlHelper2.publicQuery = true;\n * urlHelper2.nodeId = 234;\n * urlHelper2.sourceId = 'c';\n * const range2 = await new DatumRangeFinder([urlHelper, urlHelper2]).fetch();\n *\n * @example\n * // with authentication; note the authentication must be valid for all SolarNodes!\n * const auth = new AuthorizationV2Builder('my-token');\n * auth.saveSigningKey('secret');\n * urlHelper.publicQuery = false;\n * urlHelper2.publicQuery = false;\n * const range3 = await new DatumRangeFinder([urlHelper, urlHelper2], auth).fetch();\n */\nclass DatumRangeFinder extends JsonClientSupport {\n\t/**\n\t * Constructor.\n\t *\n\t * @param {NodeDatumUrlHelper|NodeDatumUrlHelper[]} urlHelpers the helper(s) to find the avaialble data range for\n\t * @param {AuthorizationV2Builder} [authBuilder] the auth builder to authenticate requests with; if not provided\n\t *                                               then only public data can be queried; when provided a pre-signed\n\t *                                               key must be available\n\t */\n\tconstructor(urlHelpers, authBuilder) {\n\t\tsuper(authBuilder);\n\t\tObject.defineProperties(this, {\n\t\t\t/**\n\t\t\t * The class version.\n\t\t\t *\n\t\t\t * @memberof DatumRangeFinder\n\t\t\t * @readonly\n\t\t\t * @type {string}\n\t\t\t */\n\t\t\tversion: { value: \"1.0.0\" }\n\t\t});\n\n\t\t/**\n\t\t * @type {NodeDatumUrlHelper[]}\n\t\t * @private\n\t\t */\n\t\tthis._helpers = Array.isArray(urlHelpers)\n\t\t\t? urlHelpers\n\t\t\t: urlHelpers\n\t\t\t? [urlHelpers]\n\t\t\t: [new NodeDatumUrlHelper()];\n\t}\n\n\t/**\n\t * Asynchronously find the available datum range using a callback.\n\t *\n\t * @param {DatumRangeFinder~dataCallback} callback the callback function to invoke\n\t * @returns {void}\n\t */\n\tload(callback) {\n\t\tconst q = queue();\n\t\tconst jsonClient = this.client();\n\t\tconst auth = this.authBuilder;\n\t\tfor (const urlHelper of this._helpers) {\n\t\t\tconst url = urlHelper.reportableIntervalUrl();\n\t\t\tconst req = jsonClient(url).on(\"beforesend\", request => {\n\t\t\t\tif (auth && auth.signingKeyValid) {\n\t\t\t\t\tauth.reset()\n\t\t\t\t\t\t.snDate(true)\n\t\t\t\t\t\t.url(url, true);\n\t\t\t\t\trequest.setRequestHeader(HttpHeaders.X_SN_DATE, auth.requestDateHeaderValue);\n\t\t\t\t\trequest.setRequestHeader(HttpHeaders.AUTHORIZATION, auth.buildWithSavedKey());\n\t\t\t\t}\n\t\t\t});\n\t\t\tq.defer(req.get, null);\n\t\t}\n\t\tq.awaitAll((error, results) => {\n\t\t\tif (error) {\n\t\t\t\tlog.error(\"Error requesting available data range: %s\", error);\n\t\t\t\tif (typeof callback === \"function\") {\n\t\t\t\t\tcallback(error);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tvar intervalObj = extractReportableInterval(results);\n\t\t\tif (intervalObj.startDateMillis !== undefined) {\n\t\t\t\tintervalObj.sDate = new Date(intervalObj.startDateMillis);\n\t\t\t}\n\t\t\tif (intervalObj.endDateMillis !== undefined) {\n\t\t\t\tintervalObj.eDate = new Date(intervalObj.endDateMillis);\n\t\t\t}\n\n\t\t\tif (typeof callback === \"function\") {\n\t\t\t\tcallback(null, intervalObj);\n\t\t\t}\n\t\t});\n\t}\n}\n\nfunction extractReportableInterval(results) {\n\tvar result,\n\t\ti = 0,\n\t\trepInterval;\n\tfor (i = 0; i < results.length; i += 1) {\n\t\trepInterval = results[i];\n\t\tif (repInterval.data === undefined || repInterval.data.endDate === undefined) {\n\t\t\tlog.debug(\n\t\t\t\t\"No data available for %s sources %s\",\n\t\t\t\tthis._helpers[i].nodeId,\n\t\t\t\tthis._helpers[i].sourceIds.join(\",\")\n\t\t\t);\n\t\t\tcontinue;\n\t\t}\n\t\trepInterval = repInterval.data;\n\t\tif (result === undefined) {\n\t\t\tresult = repInterval;\n\t\t} else {\n\t\t\t// merge start/end dates\n\t\t\t// note we don't copy the time zone... this breaks when the tz are different!\n\t\t\tif (repInterval.endDateMillis > result.endDateMillis) {\n\t\t\t\tresult.endDateMillis = repInterval.endDateMillis;\n\t\t\t\tresult.endDate = repInterval.endDate;\n\t\t\t}\n\t\t\tif (repInterval.startDateMillis < result.startDateMillis) {\n\t\t\t\tresult.startDateMillis = repInterval.startDateMillis;\n\t\t\t\tresult.startDate = repInterval.startDate;\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n}\n\nexport default DatumRangeFinder;\n","import {\n\tDatumFilter,\n\tDatumReadingTypes,\n\tHttpHeaders,\n\tLogger as log,\n\tNodeDatumUrlHelper,\n\tPagination,\n\turlQuery\n} from \"solarnetwork-api-core\";\n\nimport { queue } from \"d3-queue\";\nimport JsonClientSupport from \"./jsonClientSupport\";\n\n/**\n * @typedef {Object} Datum\n * @property {string} created the datum date\n * @property {string} sourceId the control ID\n */\n\n/**\n * The data callback function.\n *\n * @callback DatumLoader~dataCallback\n * @param {Error} [error] an error if a failure occurred\n * @param {Datum[]} data the result data\n * @param {boolean} [done] in incremental mode, will be `true` when invoked on the *last* page of data\n * @param {Pagination} [page] in incremental mode, the page associated with the data\n */\n\n/**\n * Load data for a set of source IDs, date range, and aggregate level using either the `listDatumUrl()`\n * or `datumReadingUrl()` URLs of `NodeDatumUrlHelperMixin` (the `/datum/list` or `/datum/reading`\n * endpoints).\n *\n * This object is designed to be used once per query. After creating the object and configuring an\n * asynchronous callback function with {@link DatumLoader#callback}, call {@link DatumLoader#load}\n * to start loading the data. The callback function will be called once all data has been loaded. The\n * callback function can also be passed as an argument to the {@link DatumLoader#load} method directly.\n *\n * @implements {Loader}\n * @extends {JsonClientSupport}\n * @example\n * const filter = new DatumFilter();\n * filter.nodeId = 123;\n * // configure other filter settings here...\n *\n * const urlHelper = new NodeDatumUrlHelper();\n *\n * new DatumLoader(urlHelper, filter).load((error, results) => {\n *   // results is an array of Datum objects\n * });\n * @version 1.2.0\n */\nclass DatumLoader extends JsonClientSupport {\n\t/**\n\t * Constructor.\n\t *\n\t * @param {NodeDatumUrlHelperMixin} urlHelper a URL helper for accessing node datum via SolarQuery\n\t * @param {DatumFilter} filter the filter parameters to use\n\t * @param {AuthorizationV2Builder} [authBuilder] the auth builder to authenticate requests with; if not provided\n\t *                                               then only public data can be queried; when provided a pre-signed\n\t *                                               key must be available\n\t */\n\tconstructor(urlHelper, filter, authBuilder) {\n\t\tsuper(authBuilder);\n\t\tObject.defineProperties(this, {\n\t\t\t/**\n\t\t\t * The class version.\n\t\t\t *\n\t\t\t * @memberof DatumLoader\n\t\t\t * @readonly\n\t\t\t * @type {string}\n\t\t\t */\n\t\t\tversion: { value: \"1.2.0\" }\n\t\t});\n\n\t\t/** @type {NodeDatumUrlHelper} */\n\t\tthis.urlHelper = urlHelper || new NodeDatumUrlHelper();\n\t\tif (!authBuilder) {\n\t\t\turlHelper.publicQuery = true;\n\t\t}\n\n\t\t/** @type {DatumFilter} */\n\t\tthis.filter =\n\t\t\tfilter ||\n\t\t\tnew DatumFilter({\n\t\t\t\tnodeIds: this.urlHelper.nodeIds,\n\t\t\t\twithoutTotalResultsCount: true\n\t\t\t});\n\n\t\t/**\n\t\t * @type {number}\n\t\t * @private\n\t\t */\n\t\tthis._pageSize = 1000;\n\n\t\t/**\n\t\t * @type {boolean}\n\t\t * @private\n\t\t */\n\t\tthis._includeTotalResultsCount = false;\n\n\t\t/**\n\t\t * @type {DatumLoader~dataCallback}\n\t\t * @private\n\t\t */\n\t\tthis._finishedCallback = undefined;\n\n\t\t/**\n\t\t * @type {object}\n\t\t * @private\n\t\t */\n\t\tthis._urlParameters = undefined;\n\n\t\t/**\n\t\t * When `true` then call the callback function for every page of data as it becomes available.\n\t\t * Otherwise the callback function will be invoked only after all data has been loaded.\n\t\t * @type {boolean}\n\t\t * @private\n\t\t */\n\t\tthis._incrementalMode = false;\n\n\t\t/**\n\t\t * When `true` then invoke the `/datum/reading` endpoint to load data, otherwise use `/datum/list`.\n\t\t * @type {boolean}\n\t\t * @private\n\t\t */\n\t\tthis._readingsMode = false;\n\n\t\t/**\n\t\t * An optional proxy URL to use instead of the host returned by the configured `NodeDatumUrlHelperMixin`.\n\t\t * This should be configured as an absolute URL to the proxy target, e.g. `https://query.solarnetwork.net/1m`.\n\t\t * @type {string}\n\t\t * @private\n\t\t */\n\t\tthis._proxyUrl = undefined;\n\n\t\t/**\n\t\t * When > 0 then make one request that includes the total result count and first page of\n\t\t * results, followed by parallel requests for the remaining pages.\n\t\t * @type {number}\n\t\t * @private\n\t\t */\n\t\tthis._concurrency = 0;\n\n\t\t/**\n\t\t * A queue to use for parallel mode, when `concurrency` configured > 0.\n\t\t * @type {queue}\n\t\t * @private\n\t\t */\n\t\tthis._queue = null;\n\n\t\t/**\n\t\t * @type {number}\n\t\t * @private\n\t\t */\n\t\tthis._state = 0;\n\n\t\t/**\n\t\t * @type {Datum[]}\n\t\t * @private\n\t\t */\n\t\tthis._results = undefined;\n\t}\n\n\t/**\n\t * Get or set the concurrency limit to use for parallel requests.\n\t *\n\t * By default requests are not made in parallel (this property is configured as `0`). Change\n\t * to a positive number to enable parallel query mode.\n\t *\n\t * When parallel mode is enabled the loader will make one request that includes\n\t * the total result count and first page of results, followed by parallel requests for any remaining pages\n\t * based on that total result count and configured page size.\n\t *\n\t * @param {number} [value] the concurrency level to use, or `Infinity` for no limit\n\t * @returns {number|DatumLoader} when used as a getter, the current concurrency value, otherwise this object\n\t * @since 1.1.0\n\t */\n\tconcurrency(value) {\n\t\tif (value === undefined) {\n\t\t\treturn this._concurrency;\n\t\t}\n\t\tif (!isNaN(value) && Number(value) > 0) {\n\t\t\tthis._concurrency = Number(value);\n\t\t}\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set the callback function, invoked after all data has been loaded. The callback\n\t * function will be passed two arguments: an error and the results. In incremental mode,\n\t * the callback will also be passed a boolean that will be `true` on that last page of data,\n\t * and a `Pagination` that details which page the callback represents.\n\t *\n\t * @param {DatumLoader~dataCallback} [value] the callback function to use\n\t * @returns  {DatumLoader~dataCallback|DatumLoader} when used as a getter, the current callback function, otherwise this object\n\t */\n\tcallback(value) {\n\t\tif (!value) {\n\t\t\treturn this._finishedCallback;\n\t\t}\n\t\tif (typeof value === \"function\") {\n\t\t\tthis._finishedCallback = value;\n\t\t}\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set additional URL parameters. The parameters are set as object properties.\n\t * If a property value is an array, multiple parameters for that property will be added.\n\t *\n\t * @param {object} [value] the URL parameters to include with the JSON request\n\t * @returns {object|DatumLoader} when used as a getter, the URL parameters, otherwise this object\n\t */\n\tparameters(value) {\n\t\tif (!value) return this._urlParameters;\n\t\tif (typeof value === \"object\") {\n\t\t\tthis._urlParameters = value;\n\t\t}\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set _incremental mode_ for loading the data.\n\t *\n\t * When incremental mode is enabled (set to `true`) then the callback function will be invoked\n\t * for _each result page_ that is loaded. The function will be passed a second `boolean` argument\n\t * that will be set to `true` only on the last page of result data, and a third Pagination`\n\t * object argument that details the starting offset of the page.\n\t *\n\t * When incremental mode is disabled (set to `false`, the default) then all result pages are\n\t * combined into a single array and the callback will be invoked just once.\n\t *\n\t * @param {boolean} [value] the incremental mode to set\n\t * @returns {boolean|DatumLoader} when used a a getter, the incremental mode; otherwise this object\n\t */\n\tincremental(value) {\n\t\tif (value === undefined) return this._incrementalMode;\n\t\tthis._incrementalMode = !!value;\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set the result pagination size.\n\t *\n\t * @param {number} [value] the pagination size to set; defaults to `1000`\n\t * @returns {number|DatumLoader} when used as a getter, the pagination size; otherwise this object\n\t */\n\tpaginationSize(value) {\n\t\tif (isNaN(Number(value))) return this._pageSize;\n\t\tthis._pageSize = value;\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set the flag for requesting the total results count.\n\t *\n\t * By default the datum loader will _not_ request the overal total result count when querying\n\t * for data, as this speeds up queries. By setting this to `true` the total result count will\n\t * be requested on the _first_ query page.\n\t *\n\t * @param {boolean} [value] the flag to include total results count\n\t * @returns {boolean|DatumLoader} when used a a getter, the total results count inclusion mode; otherwise this object\n\t */\n\tincludeTotalResultsCount(value) {\n\t\tif (value === undefined) return this._includeTotalResultsCount;\n\t\tthis._includeTotalResultsCount = !!value;\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set _readings mode_ for loading the data.\n\t *\n\t * When readings mode is enabled (set to `true`) then the `/datum/reading` endpoint will be invoked\n\t * to load data.\n\t *\n\t * When readings mode is disabled (set to `false`, the default) then the `/datum/list` endpoint will\n\t * be invoked to load data.\n\t *\n\t * @param {boolean} [value] the readings mode to set\n\t * @returns {boolean|DatumLoader} when used a a getter, the readings mode; otherwise this object\n\t */\n\treadings(value) {\n\t\tif (value === undefined) return this._readingsMode;\n\t\tthis._readingsMode = !!value;\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set the URL to a proxy to use for loading the data.\n\t *\n\t * This can be configured as an absolute URL to the proxy server to use instead of making requests\n\t * directly to the URL returned by the configured `NodeDatumUrlHelperMixin`. For example:\n\t *\n\t * * https://query.solarnetwork.net\n\t * * https://query.solarnetwork.net/1m\n\t *\n\t * @param {string} [value] the proxy URL to set, or `null` or an empty string to not use any proxy\n\t * @returns {string|DatumLoader} when used a a getter, the readings mode; otherwise this object\n\t */\n\tproxyUrl(value) {\n\t\tif (value === undefined) return this._proxyUrl;\n\t\tthis._proxyUrl = value ? value : undefined;\n\t\treturn this;\n\t}\n\n\t/**\n\t * Initiate loading the data.\n\t *\n\t * As an alternative to configuring the callback function via the {@link DatumLoader#callback}\n\t * method,a callback function can be passed as an argument to this function. That allows this\n\t * function to be passed to things like `queue.defer`, for example.\n\t *\n\t * @param {DatumLoader~dataCallback} [callback] a callback function to use; either this argument must be provided\n\t *                              or the function must have already been configured via {@link DatumLoader#callback}\n\t * @returns {DatumLoader} this object\n\t */\n\tload(callback) {\n\t\t// to support queue use, allow callback to be passed directly to this function\n\t\tif (typeof callback === \"function\") {\n\t\t\tthis._finishedCallback = callback;\n\t\t}\n\t\tthis._state = 1;\n\t\tif (this._concurrency > 0) {\n\t\t\tthis._queue = queue(this._concurrency === Infinity ? null : this._concurrency);\n\t\t}\n\t\tthis.loadData(new Pagination(this._pageSize, 0));\n\t\treturn this;\n\t}\n\n\t/**\n\t * Invoke the configured callback function.\n\t *\n\t * @param {Error} [error] an optional  error\n\t * @param {boolean} done `true` if there is no more data to load\n\t * @param {Pagination} [page] the incremental mode page\n\t * @returns {void}\n\t * @private\n\t */\n\thandleResults(error, done, page) {\n\t\tif (done) {\n\t\t\tthis._state = 2; // done\n\t\t}\n\n\t\tif (this._finishedCallback) {\n\t\t\tlet args = [error, this._results];\n\t\t\tif (this._incrementalMode) {\n\t\t\t\targs.push(done);\n\t\t\t\targs.push(page);\n\t\t\t}\n\t\t\tthis._finishedCallback.apply(this, args);\n\t\t}\n\t}\n\n\t/**\n\t * Load a single page of data, starting at a specific offset.\n\t *\n\t * @param {Pagination} [page] the page to load\n\t * @returns {void}\n\t * @private\n\t */\n\tloadData(page) {\n\t\tconst auth = this.authBuilder;\n\t\tconst q = this._queue;\n\t\tlet pagination = page instanceof Pagination ? page : new Pagination();\n\t\tconst queryFilter = new DatumFilter(this.filter);\n\t\tqueryFilter.withoutTotalResultsCount =\n\t\t\t(this._includeTotalResultsCount || q) && pagination.offset === 0 ? false : true;\n\n\t\tlet url = this._readingsMode\n\t\t\t? this.urlHelper.datumReadingUrl(\n\t\t\t\t\tqueryFilter,\n\t\t\t\t\tDatumReadingTypes.Difference,\n\t\t\t\t\tundefined,\n\t\t\t\t\tundefined,\n\t\t\t\t\tpagination\n\t\t\t  )\n\t\t\t: this.urlHelper.listDatumUrl(queryFilter, undefined, pagination);\n\t\tif (this._urlParameters) {\n\t\t\tlet queryParams = urlQuery.urlQueryEncode(this._urlParameters);\n\t\t\tif (queryParams) {\n\t\t\t\turl += \"&\" + queryParams;\n\t\t\t}\n\t\t}\n\t\tconst reqUrl = this._proxyUrl ? url.replace(/^[^:]+:\\/\\/[^/]+/, this._proxyUrl) : url;\n\t\tconst jsonClient = this.client();\n\t\tconst req = jsonClient(reqUrl)\n\t\t\t.on(\"beforesend\", request => {\n\t\t\t\tif (auth && auth.signingKeyValid) {\n\t\t\t\t\tauth.reset()\n\t\t\t\t\t\t.snDate(true)\n\t\t\t\t\t\t.url(url, true);\n\t\t\t\t\trequest.setRequestHeader(HttpHeaders.X_SN_DATE, auth.requestDateHeaderValue);\n\t\t\t\t\trequest.setRequestHeader(HttpHeaders.AUTHORIZATION, auth.buildWithSavedKey());\n\t\t\t\t}\n\t\t\t})\n\t\t\t.on(\"load\", json => {\n\t\t\t\tlet dataArray = datumExtractor(json);\n\t\t\t\tif (dataArray === undefined) {\n\t\t\t\t\tlog.debug(\"No data available for %s\", reqUrl);\n\t\t\t\t\tif (!q) {\n\t\t\t\t\t\tthis.handleResults();\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tconst incMode = this._incrementalMode;\n\t\t\t\tconst nextOffset = offsetExtractor(json, pagination);\n\t\t\t\tconst totalResults = json && json.data ? json.data.totalResults : null;\n\n\t\t\t\tif (this._results === undefined || incMode) {\n\t\t\t\t\tthis._results = dataArray;\n\n\t\t\t\t\t// discover page size, if pagination does not already have one\n\t\t\t\t\tif (pagination.max < 1) {\n\t\t\t\t\t\tconst max = pageSizeExtractor(json);\n\t\t\t\t\t\tif (max > 0) {\n\t\t\t\t\t\t\tpagination = new Pagination(max, pagination.offset);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (incMode) {\n\t\t\t\t\t\tthis.handleResults(undefined, nextOffset < 1, pagination);\n\t\t\t\t\t}\n\t\t\t\t} else if (!q) {\n\t\t\t\t\tthis._results = this._results.concat(dataArray);\n\t\t\t\t}\n\n\t\t\t\t// see if we need to load more results\n\t\t\t\tif (nextOffset > 0 || (q && pagination.offset > 0)) {\n\t\t\t\t\tif (q) {\n\t\t\t\t\t\tif (totalResults > 0) {\n\t\t\t\t\t\t\t// parallel mode with first page results; queue all remaining pages\n\t\t\t\t\t\t\tfor (\n\t\t\t\t\t\t\t\tlet pOffset = nextOffset;\n\t\t\t\t\t\t\t\tpOffset < totalResults;\n\t\t\t\t\t\t\t\tpOffset += pagination.max\n\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\tthis.loadData(pagination.withOffset(pOffset));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tq.awaitAll((error, allResults) => {\n\t\t\t\t\t\t\t\tif (\n\t\t\t\t\t\t\t\t\t!error &&\n\t\t\t\t\t\t\t\t\tallResults &&\n\t\t\t\t\t\t\t\t\tallResults.findIndex(el => el === undefined) >= 0\n\t\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\t\t// some result is unexpectedly undefined; seen this under Node from\n\t\t\t\t\t\t\t\t\t// https://github.com/driverdan/node-XMLHttpRequest/issues/162\n\t\t\t\t\t\t\t\t\t// where the HTTP client lib is not reporting back an actual error value\n\t\t\t\t\t\t\t\t\t// when something happens like a response timeout\n\t\t\t\t\t\t\t\t\terror = new Error(\n\t\t\t\t\t\t\t\t\t\t\"One or more requests did not return a result, but no error was reported.\"\n\t\t\t\t\t\t\t\t\t);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif (!error) {\n\t\t\t\t\t\t\t\t\tallResults\n\t\t\t\t\t\t\t\t\t\t.map(function(qJson) {\n\t\t\t\t\t\t\t\t\t\t\treturn datumExtractor(qJson) || [];\n\t\t\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t\t\t\t.forEach(resultArray => {\n\t\t\t\t\t\t\t\t\t\t\tthis._results = this._results.concat(resultArray);\n\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tthis.handleResults(error !== null ? error : undefined, true);\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tthis.loadData(pagination.withOffset(nextOffset));\n\t\t\t\t\t}\n\t\t\t\t} else if (!incMode) {\n\t\t\t\t\tthis.handleResults(undefined, true);\n\t\t\t\t}\n\t\t\t})\n\t\t\t.on(\"error\", error => {\n\t\t\t\tlog.error(\"Error requesting data for %s: %s\", reqUrl, error);\n\t\t\t\tthis.handleResults(new Error(`Error requesting data for ${reqUrl}: ${error}`));\n\t\t\t});\n\t\tif (q && pagination.offset > 0) {\n\t\t\tq.defer(req.get, null);\n\t\t} else {\n\t\t\treq.get();\n\t\t}\n\t}\n}\n\n/**\n * Extract the datum list from the returned data.\n *\n * @param {object} json the JSON results to extract from\n * @returns {Datum[]} the extracted data\n * @private\n */\nfunction datumExtractor(json) {\n\tif (\n\t\t!json ||\n\t\tjson.success !== true ||\n\t\tjson.data === undefined ||\n\t\tArray.isArray(json.data.results) !== true\n\t) {\n\t\treturn undefined;\n\t}\n\treturn json.data.results;\n}\n\n/**\n * Extract the page size from the returned data.\n *\n * @param {object} json the JSON results to extract from\n * @returns {number} the extracted page size\n * @private\n */\nfunction pageSizeExtractor(json) {\n\tif (!(json && json.data)) {\n\t\treturn 0;\n\t}\n\tconst data = json.data;\n\treturn data.returnedResultCount + data.startingOffset < data.totalResults\n\t\t? data.returnedResultCount\n\t\t: 0;\n}\n\n/**\n * Extract the \"next\" offset to use based on the returned data.\n *\n * If `page` is supplied, then pagination will be based on `page.max` and will continue\n * until less than that many results are returned. If `page` is not supplied, then\n * pagination will be based on `data.returnedResultCount` and will continue until\n * `data.totalResults` has been returned.\n *\n * @param {object} json the JSON results to extract from\n * @param {Pagination} [page] the incremental mode page\n * @returns {number} the extracted offset, or `0` if no more pages to return\n * @private\n */\nfunction offsetExtractor(json, page) {\n\tif (!(json && json.data)) {\n\t\treturn 0;\n\t}\n\tconst data = json.data;\n\tif (page && page.max) {\n\t\t// don't bother with totalResults; just keep going unless returnedResultCount < page.max\n\t\treturn data.returnedResultCount < page.max ? 0 : data.startingOffset + page.max;\n\t}\n\treturn data.returnedResultCount + data.startingOffset < data.totalResults\n\t\t? data.returnedResultCount + data.startingOffset\n\t\t: 0;\n}\n\nexport default DatumLoader;\n","import { json } from \"d3-request\";\n\n/**\n * The data callback function.\n *\n * @callback JsonClientSupport~dataCallback\n * @param {Error} [error] an error if a failure occurred\n * @param {*} data the result data\n */\n\n/**\n * An abstract class with customizable JSON client support.\n *\n * @abstract\n */\nclass JsonClientSupport {\n\t/**\n\t * Constructor.\n\t *\n\t * @param {AuthorizationV2Builder} [authBuilder] the auth builder to authenticate requests with; if not provided\n\t *                                               then only public data can be queried\n\t */\n\tconstructor(authBuilder) {\n\t\t/**\n\t\t * An authorization builder to use to make authenticated HTTP requests.\n\t\t * @type {AuthorizationV2Builder}\n\t\t * @protected\n\t\t */\n\t\tthis.authBuilder = authBuilder;\n\n\t\t/**\n\t\t * The JSON client.\n\t\t * @private\n\t\t */\n\t\tthis.jsonClient = json;\n\t}\n\n\t/**\n\t * Get or set a JSON HTTP client function to use.\n\t *\n\t * The function must be compatible with `d3.json` and defaults to that. This provides a way\n\t * to integrate a different HTTP client if needed, for example a mock implementation in tests.\n\t *\n\t * @param {function} [value] the JSON client function, compatible with `d3.json`\n\t * @returns {function|DatumSourceFinder} when used as a getter, the JSON client function, otherwise this object\n\t */\n\tclient(value) {\n\t\tif (!value) return this.jsonClient;\n\t\tif (typeof value === \"function\") {\n\t\t\tthis.jsonClient = value;\n\t\t}\n\t\treturn this;\n\t}\n\n\t/**\n\t * Asynchronously load the data.\n\t *\n\t * This method calls {@link JsonClientSupport#load} to perform the actual work.\n\t *\n\t * @returns {Promise<*>} the result promise\n\t */\n\tfetch() {\n\t\treturn new Promise((resolve, reject) => {\n\t\t\tthis.load((error, results) => {\n\t\t\t\tif (error) {\n\t\t\t\t\treject(error);\n\t\t\t\t} else {\n\t\t\t\t\tresolve(results);\n\t\t\t\t}\n\t\t\t});\n\t\t});\n\t}\n\n\t/**\n\t * Asynchronously load the data using a callback.\n\t *\n\t * Extending classes must override this method to provide a useful implementation.\n\t *\n\t * @abstract\n\t * @param {JsonClientSupport~dataCallback} callback the callback function to invoke\n\t * @returns {void}\n\t */\n\tload(callback) {\n\t\tcallback(new Error(\"Abstract method must be implemented by subclass.\"));\n\t}\n}\n\nexport default JsonClientSupport;\n","import { queue } from \"d3-queue\";\nimport { DatumFilter, HttpHeaders, Logger as log, NodeDatumUrlHelper } from \"solarnetwork-api-core\";\n\nimport JsonClientSupport from \"./jsonClientSupport\";\n\n/**\n * The data callback function.\n *\n * @callback DatumSourceFinder~dataCallback\n * @param {Error} [error] an error if a failure occurred\n * @param {object} data the result data, with node ID keys and `string[]` values representing the source IDs\n */\n\n/**\n * Class to find the available datum sources for a set of node datum URL helpers.\n *\n * This helper is useful for finding what source IDs are avaialble for a set of nodes.\n * It returns an object with node ID properties with associated source ID array values,\n * for example:\n *\n * ```\n * { 123: [\"a\", \"b\", \"c\"] }\n * ```\n * @extends {JsonClientSupport}\n * @example\n * // the simple case, all available sources for just one SolarNode\n * const urlHelper = new NodeDatumUrlHelper();\n * urlHelper.publicQuery = true;\n * urlHelper.nodeId = 123;\n * const sources = await new DatumSourceFinder(urlHelper).fetch();\n *\n * @example\n * // find all sources matching a wildcard pattern within the past day\n * const filter = new DatumFilter();\n * filter.startDate = new Date(Date.now() - 24 * 60 * 60 * 1000);\n * filter.sourceId = '/power/**';\n * const sources2 = await new DatumSourceFinder(urlHelper).filter(filter).fetch();\n *\n * @example\n * // find all sources across multiple SolarNodes\n * const urlHelper2 = new NodeDatumUrlHelper();\n * urlHelper2.publicQuery = true;\n * urlHelper2.nodeId = 234;\n * const sources3 = await new DatumSourceFinder([urlHelper, urlHelper2]).fetch();\n */\nclass DatumSourceFinder extends JsonClientSupport {\n\t/**\n\t * Constructor.\n\t *\n\t * @param {NodeDatumUrlHelper|NodeDatumUrlHelper[]} urlHelpers the helper(s) to find the avaialble sources for\n\t * @param {AuthorizationV2Builder} [authBuilder] the auth builder to authenticate requests with; if not provided\n\t *                                               then only public data can be queried; when provided a pre-signed\n\t *                                               key must be available\n\t */\n\tconstructor(urlHelpers, authBuilder) {\n\t\tsuper(authBuilder);\n\t\tObject.defineProperties(this, {\n\t\t\t/**\n\t\t\t * The class version.\n\t\t\t *\n\t\t\t * @memberof DatumSourceFinder\n\t\t\t * @readonly\n\t\t\t * @type {string}\n\t\t\t */\n\t\t\tversion: { value: \"1.0.0\" }\n\t\t});\n\n\t\t/**\n\t\t * @type {NodeDatumUrlHelper[]}\n\t\t * @private\n\t\t */\n\t\tthis._helpers = Array.isArray(urlHelpers)\n\t\t\t? urlHelpers\n\t\t\t: urlHelpers\n\t\t\t? [urlHelpers]\n\t\t\t: [new NodeDatumUrlHelper()];\n\t}\n\n\t/**\n\t * Get or set a `DatumFilter` to limit the query with.\n\t *\n\t * The `startDate`, `endDate`, and `metadataFilter` properties can be used to limit the query scope.\n\t *\n\t * @param {DatumFilter} [value] the datum filter to use\n\t * @returns {function|DatumFilter} when used as a getter, the filter, otherwise this object\n\t */\n\tfilter(value) {\n\t\tif (!value) return this.datumFilter;\n\t\tif (value instanceof DatumFilter) {\n\t\t\tthis.datumFilter = value;\n\t\t}\n\t\treturn this;\n\t}\n\n\t/**\n\t * Asynchronously find the available datum range using a callback.\n\t *\n\t * @param {DatumSourceFinder~dataCallback} callback the callback function to invoke\n\t * @returns {void}\n\t */\n\tload(callback) {\n\t\tconst q = queue();\n\t\tconst jsonClient = this.client();\n\t\tconst auth = this.authBuilder;\n\t\tconst requestKeys = [];\n\n\t\tfunction addRequest(key, url) {\n\t\t\trequestKeys.push(key);\n\t\t\tconst req = jsonClient(url).on(\"beforesend\", request => {\n\t\t\t\tif (auth && auth.signingKeyValid) {\n\t\t\t\t\tauth.reset()\n\t\t\t\t\t\t.snDate(true)\n\t\t\t\t\t\t.url(url, true);\n\t\t\t\t\trequest.setRequestHeader(HttpHeaders.X_SN_DATE, auth.requestDateHeaderValue);\n\t\t\t\t\trequest.setRequestHeader(HttpHeaders.AUTHORIZATION, auth.buildWithSavedKey());\n\t\t\t\t}\n\t\t\t});\n\t\t\tq.defer(req.get, null);\n\t\t}\n\t\tfor (const urlHelper of this._helpers) {\n\t\t\tconst filter = new DatumFilter(this.datumFilter);\n\t\t\tfilter.nodeIds = urlHelper.nodeIds;\n\t\t\tif (filter.metadataFilter || filter.nodeIds.length === 1) {\n\t\t\t\t// when metadata filter used, multiple node IDs allowed\n\t\t\t\taddRequest(\n\t\t\t\t\tthis.metadataFilter ? null : filter.nodeId,\n\t\t\t\t\turlHelper.availableSourcesUrl(filter)\n\t\t\t\t);\n\t\t\t} else {\n\t\t\t\t// no metadata filter, or multiple node IDs, so add one node ID at a time\n\t\t\t\tfor (const nodeId of filter.nodeIds) {\n\t\t\t\t\tconst oneFilter = new DatumFilter(filter);\n\t\t\t\t\toneFilter.nodeId = nodeId;\n\t\t\t\t\taddRequest(nodeId, urlHelper.availableSourcesUrl(oneFilter));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tq.awaitAll((error, results) => {\n\t\t\tif (error) {\n\t\t\t\tlog.error(\"Error requesting available sources: %s\", error);\n\t\t\t\tif (typeof callback === \"function\") {\n\t\t\t\t\tcallback(error);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tconst result = {};\n\n\t\t\tfor (let i = 0, len = results.length; i < len; i += 1) {\n\t\t\t\tconst data = Array.isArray(results[i].data) ? results[i].data : undefined;\n\t\t\t\tif (!data) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tconst key = requestKeys[i];\n\t\t\t\tif (key === null) {\n\t\t\t\t\t// result is array of nodeId/soruceId pairs, e.g. {nodeId:1, sourceId:\"foo\"}\n\t\t\t\t\tfor (const pair of data) {\n\t\t\t\t\t\tlet nodeIds = result[pair.nodeId];\n\t\t\t\t\t\tif (!nodeIds) {\n\t\t\t\t\t\t\tnodeIds = [];\n\t\t\t\t\t\t\tresult[pair.nodeId] = nodeIds;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (nodeIds.indexOf(pair.sourceId) < 0) {\n\t\t\t\t\t\t\tnodeIds.push(pair.sourceId);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\t// result is array of sourceIds\n\t\t\t\t\tlet nodeIds = result[key];\n\t\t\t\t\tif (!nodeIds) {\n\t\t\t\t\t\tresult[key] = data;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tfor (const sourceId of data) {\n\t\t\t\t\t\t\tif (nodeIds.indexOf(sourceId) < 0) {\n\t\t\t\t\t\t\t\tnodeIds.push(sourceId);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (typeof callback === \"function\") {\n\t\t\t\tcallback(null, result);\n\t\t\t}\n\t\t});\n\t}\n}\n\nexport default DatumSourceFinder;\n","import { queue } from \"d3-queue\";\n\n/**\n * Interface for classes that can be used to load data for {@link MultiLoader}.\n *\n * @interface Loader\n */\n\n/**\n * The loader callback function.\n *\n * @callback Loader~dataCallback\n * @param {Error} [error] an error if a failure occurred\n * @param {Object} data the result data\n */\n\n/**\n * Load data asynchronously with a callback.\n *\n * @function\n * @name Loader#load\n * @param {Loader~dataCallback} callback the callback to invoke with the results\n * @returns {Loader} the loader object\n */\n\n/**\n * The data callback function.\n *\n * @callback MultiLoader~dataCallback\n * @param {Error} [error] an error if a failure occurred\n * @param {Object[]} data the result data from all loaders\n */\n\n/**\n * Load data from multiple {@link Loader} objects, invoking a callback function\n * after all data has been loaded. Call {@link MultiLoader#load} to start loading the data.\n *\n * The {@link DatumLoader} class conforms to the {@link Loader} interface, so can be used to\n * load arrays of {@link Datum} objects based on search criteria.\n *\n * @example\n * const filter1 = new DatumFilter();\n * filter1.nodeId = 123;\n * // configure other filter settings here...\n *\n * const filter2 = new DatumFilter();\n * filter2.nodeId = 234;\n * // configure other filter settings here\n *\n * const urlHelper = new NodeDatumUrlHelper();\n *\n * new MultiLoader([\n *   new DatumLoader(urlHelper, filter1),\n *   new DatumLoader(urlHelper, filter2),\n * ]).load((error, results) => {\n *   // results is a 2-element array of Datum arrays\n * });\n *\n * @version 1.1.0\n */\nclass MultiLoader {\n\t/**\n\t * Constructor.\n\t *\n\t * @param {Loader[]} loaders - array of loader objects\n\t */\n\tconstructor(loaders) {\n\t\tObject.defineProperties(this, {\n\t\t\t/**\n\t\t\t * The class version.\n\t\t\t *\n\t\t\t * @memberof MultiLoader\n\t\t\t * @readonly\n\t\t\t * @type {string}\n\t\t\t */\n\t\t\tversion: { value: \"1.1.0\" }\n\t\t});\n\n\t\t/**\n\t\t * @type {Loader[]}\n\t\t * @private\n\t\t */\n\t\tthis._loaders = loaders;\n\n\t\t/**\n\t\t * @type {MultiLoader~dataCallback}\n\t\t * @private\n\t\t */\n\t\tthis._finishedCallback = undefined;\n\n\t\t/**\n\t\t * @type {number}\n\t\t * @private\n\t\t */\n\t\tthis._concurrency = Infinity;\n\t}\n\n\t/**\n\t * Get or set the concurrency limit to use for requets.\n\t *\n\t * A default, infinite concurrency queue will be used by default.\n\t *\n\t * @param {number} [value] the concurrency level to use, or `Infinity` for no limit\n\t * @returns {number|MultiLoader} when used as a getter, the current concurrency value, otherwise this object\n\t * @since 1.1.0\n\t */\n\tconcurrency(value) {\n\t\tif (value === undefined) {\n\t\t\treturn this._concurrency;\n\t\t}\n\t\tvar n = Number(value);\n\t\tif (!isNaN(value) && n > 0) {\n\t\t\tthis._concurrency = n;\n\t\t}\n\t\treturn this;\n\t}\n\n\t/**\n\t * Asynchronously load the data.\n\t *\n\t * This method calls {@link MultiLoader#load} to perform the actual work.\n\t *\n\t * @returns {Promise<Object[]>} the result promise\n\t */\n\tfetch() {\n\t\treturn new Promise((resolve, reject) => {\n\t\t\tthis.load((error, results) => {\n\t\t\t\tif (error) {\n\t\t\t\t\treject(error);\n\t\t\t\t} else {\n\t\t\t\t\tresolve(results);\n\t\t\t\t}\n\t\t\t});\n\t\t});\n\t}\n\n\t/**\n\t * Initiate loading the data. This will call {@link Loader#load} on each\n\t * supplied loader, in parallel. As an alternative to configuring the callback function via\n\t * the {@link MultiLoader#callback} method, a callback function can be passed as an argument\n\t * to this function. This allows this function to be passed to `queue.defer`, for example.\n\t *\n\t * @param {MultiLoader~dataCallback} [callback] a callback function to use; either this argument must be provided\n\t *                              or the function must have already been configured via  {@link MultiLoader#callback}\n\t * @returns {MultiLoader} this object\n\t */\n\tload(callback) {\n\t\t// to support queue use, allow callback to be passed directly to this function\n\t\tif (typeof callback === \"function\") {\n\t\t\tthis._finishedCallback = callback;\n\t\t}\n\t\tconst q = queue(this._concurrency);\n\t\tthis._loaders.forEach(loader => {\n\t\t\t// queue.defer will invoke the callback with a `null` `this` object, so `e.load.bind` here\n\t\t\tq.defer(loader.load.bind(loader));\n\t\t});\n\t\tq.awaitAll((error, results) => {\n\t\t\tif (this._finishedCallback) {\n\t\t\t\tthis._finishedCallback.call(this, error, results);\n\t\t\t}\n\t\t});\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set the callback function, invoked after all data has been loaded. The callback\n\t * function will be passed two arguments: an error and the results as an array of results\n\t * from each configured {@link Loader}.\n\t *\n\t * @param {MultiLoader~dataCallback} [value] the callback function to use\n\t * @returns  {MultiLoader~dataCallback|MultiLoader} when used as a getter, the current callback function, otherwise this object\n\t */\n\tcallback(value) {\n\t\tif (!value) {\n\t\t\treturn this._finishedCallback;\n\t\t}\n\t\tif (typeof value === \"function\") {\n\t\t\tthis._finishedCallback = value;\n\t\t}\n\t\treturn this;\n\t}\n}\n\nexport default MultiLoader;\n"]}