{"version":3,"sources":["../src/datumRangeFinder.js","../src/datumLoader.js","../src/jsonClientSupport.js","../src/datumSourceFinder.js","../src/multiLoader.js"],"names":["extractReportableInterval","results","result","repInterval","i","length","undefined","data","endDate","endDateMillis","startDateMillis","startDate","log","debug","this","_helpers","nodeId","sourceIds","join","datumExtractor","json","success","Array","isArray","pageSizeExtractor","returnedResultCount","startingOffset","totalResults","offsetExtractor","page","max","JsonClientSupport","authBuilder","jsonClient","value","Promise","resolve","reject","_this","load","error","callback","Error","DatumRangeFinder","urlHelpers","Object","defineProperties","_assertThisInitialized","version","NodeDatumUrlHelper","q","queue","client","auth","_step","url","reportableIntervalUrl","req","on","request","signingKeyValid","reset","snDate","setRequestHeader","HttpHeaders","X_SN_DATE","requestDateHeaderValue","AUTHORIZATION","buildWithSavedKey","defer","get","Symbol","iterator","_iteratorNormalCompletion","_iterator","next","done","awaitAll","intervalObj","sDate","Date","eDate","DatumSourceFinder","DatumFilter","datumFilter","addRequest","key","requestKeys","push","urlHelper","filter","nodeIds","metadataFilter","availableSourcesUrl","_step4","_iteratorNormalCompletion4","_iterator4","oneFilter","len","_step2","_iteratorNormalCompletion2","_iterator2","pair","indexOf","sourceId","_step3","_iteratorNormalCompletion3","_iterator3","DatumLoader","publicQuery","withoutTotalResultsCount","_pageSize","_includeTotalResultsCount","_finishedCallback","_urlParameters","_incrementalMode","_readingsMode","_proxyUrl","_concurrency","_queue","_state","_results","isNaN","Number","_typeof","Infinity","loadData","Pagination","args","apply","pagination","queryFilter","offset","datumReadingUrl","DatumReadingTypes","Difference","listDatumUrl","queryParams","urlQuery","urlQueryEncode","reqUrl","replace","dataArray","incMode","_this2","nextOffset","handleResults","concat","pOffset","withOffset","allResults","findIndex","el","map","qJson","forEach","resultArray","MultiLoader","loaders","_loaders","n","loader","bind","call"],"mappings":"84CAgJA,SAASA,0BAA0BC,OAC9BC,EAEHC,EADAC,EAAI,MAEAA,EAAI,EAAGA,EAAIH,EAAQI,OAAQD,GAAK,OAEXE,KADzBH,EAAcF,EAAQG,IACNG,WAAmDD,IAA7BH,EAAYI,KAAKC,SAQvDL,EAAcA,EAAYI,UACXD,IAAXJ,EACHA,EAASC,GAILA,EAAYM,cAAgBP,EAAOO,gBACtCP,EAAOO,cAAgBN,EAAYM,cACnCP,EAAOM,QAAUL,EAAYK,SAE1BL,EAAYO,gBAAkBR,EAAOQ,kBACxCR,EAAOQ,gBAAkBP,EAAYO,gBACrCR,EAAOS,UAAYR,EAAYQ,aAnBhCC,OAAIC,MACH,sCACAC,KAAKC,SAASX,GAAGY,OACjBF,KAAKC,SAASX,GAAGa,UAAUC,KAAK,aAoB5BhB,EC8TR,SAASiB,eAAeC,MAErBA,IACgB,IAAjBA,EAAKC,cACSf,IAAdc,EAAKb,OACgC,IAArCe,MAAMC,QAAQH,EAAKb,KAAKN,gBAIlBmB,EAAKb,KAAKN,QAUlB,SAASuB,kBAAkBJ,OACpBA,IAAQA,EAAKb,YACX,MAEFA,EAAOa,EAAKb,YACXA,EAAKkB,oBAAsBlB,EAAKmB,eAAiBnB,EAAKoB,aAC1DpB,EAAKkB,oBACL,EAgBJ,SAASG,gBAAgBR,EAAMS,OACxBT,IAAQA,EAAKb,YACX,MAEFA,EAAOa,EAAKb,YACdsB,GAAQA,EAAKC,IAETvB,EAAKkB,oBAAsBI,EAAKC,IAAM,EAAIvB,EAAKmB,eAAiBG,EAAKC,IAEtEvB,EAAKkB,oBAAsBlB,EAAKmB,eAAiBnB,EAAKoB,aAC1DpB,EAAKkB,oBAAsBlB,EAAKmB,eAChC,0LClhBEK,wCAOOC,gCAMNA,YAAcA,OAMdC,WAAab,yDAYZc,UACDA,GACgB,mBAAVA,SACLD,WAAaC,GAEZpB,MAJYA,KAAKmB,6DAejB,IAAIE,QAAQ,SAACC,EAASC,GAC5BC,EAAKC,KAAK,SAACC,EAAOvC,GACbuC,EACHH,EAAOG,GAEPJ,EAAQnC,oCAePwC,GACJA,EAAS,IAAIC,MAAM,8DFlBfC,wCASOC,EAAYZ,uGACjBA,IACNa,OAAOC,iBAAPC,uBAAAT,IAQCU,SAAWd,MAAO,aAOdnB,SAAWO,MAAMC,QAAQqB,GAC3BA,EACAA,GACCA,IACA,IAAIK,yCA9BqBlB,8DAuCzBU,OACES,EAAIC,QACJlB,EAAanB,KAAKsC,SAClBC,EAAOvC,KAAKkB,2CAClBsB,mBACOC,EALOD,EAAApB,MAKSsB,wBAChBC,EAAMxB,EAAWsB,GAAKG,GAAG,aAAc,SAAAC,GACxCN,GAAQA,EAAKO,kBAChBP,EAAKQ,QACHC,QAAO,GACPP,IAAIA,GAAK,GACXI,EAAQI,iBAAiBC,YAAYC,UAAWZ,EAAKa,wBACrDP,EAAQI,iBAAiBC,YAAYG,cAAed,EAAKe,wBAG3DlB,EAAEmB,MAAMZ,EAAIa,IAAK,SAXMxD,KAAKC,SAA7BwD,OAAAC,cAAAC,GAAAnB,EAAAoB,EAAAC,QAAAC,MAAAH,GAAA,wFAaAvB,EAAE2B,SAAS,SAACrC,EAAOvC,MACduC,SACH5B,OAAI4B,MAAM,4CAA6CA,QAC/B,mBAAbC,GACVA,EAASD,QAIPsC,EAAc9E,0BAA0BC,QACRK,IAAhCwE,EAAYpE,kBACfoE,EAAYC,MAAQ,IAAIC,KAAKF,EAAYpE,uBAERJ,IAA9BwE,EAAYrE,gBACfqE,EAAYG,MAAQ,IAAID,KAAKF,EAAYrE,gBAGlB,mBAAbgC,GACVA,EAAS,KAAMqC,cG7FbI,yCASOtC,EAAYZ,uGACjBA,IACNa,OAAOC,iBAAPC,uBAAAT,IAQCU,SAAWd,MAAO,aAOdnB,SAAWO,MAAMC,QAAQqB,GAC3BA,EACAA,GACCA,IACA,IAAIK,yCA9BsBlB,gEAyCxBG,UACDA,GACDA,aAAiBiD,mBACfC,YAAclD,GAEbpB,MAJYA,KAAKsE,yCAapB3C,YAMK4C,EAAWC,EAAK/B,GACxBgC,EAAYC,KAAKF,OACX7B,EAAMxB,EAAWsB,GAAKG,GAAG,aAAc,SAAAC,GACxCN,GAAQA,EAAKO,kBAChBP,EAAKQ,QACHC,QAAO,GACPP,IAAIA,GAAK,GACXI,EAAQI,iBAAiBC,YAAYC,UAAWZ,EAAKa,wBACrDP,EAAQI,iBAAiBC,YAAYG,cAAed,EAAKe,wBAG3DlB,EAAEmB,MAAMZ,EAAIa,IAAK,UAhBZpB,EAAIC,QACJlB,EAAanB,KAAKsC,SAClBC,EAAOvC,KAAKkB,YACZuD,oCAeNjC,IAAwBxC,KAAKC,SAA7BwD,OAAAC,cAAAC,GAAAnB,EAAAoB,EAAAC,QAAAC,MAAAH,GAAA,EAAuC,KAA5BgB,EAA4BnC,EAAApB,MAChCwD,EAAS,IAAIP,YAAYrE,KAAKsE,gBACpCM,EAAOC,QAAUF,EAAUE,QACvBD,EAAOE,gBAA4C,IAA1BF,EAAOC,QAAQtF,OAE3CgF,EACCvE,KAAK8E,eAAiB,KAAOF,EAAO1E,OACpCyE,EAAUI,oBAAoBH,QAEzB,oCAENI,IAAqBJ,EAAOC,QAA5BpB,OAAAC,cAAAuB,GAAAD,EAAAE,EAAArB,QAAAC,MAAAmB,GAAA,EAAqC,KAA1B/E,EAA0B8E,EAAA5D,MAC9B+D,EAAY,IAAId,YAAYO,GAClCO,EAAUjF,OAASA,EACnBqE,EAAWrE,EAAQyE,EAAUI,oBAAoBI,4KAKpD/C,EAAE2B,SAAS,SAACrC,EAAOvC,MACduC,SACH5B,OAAI4B,MAAM,yCAA0CA,QAC5B,mBAAbC,GACVA,EAASD,QAON,IAFCtC,KAEGE,EAAI,EAAG8F,EAAMjG,EAAQI,OAAQD,EAAI8F,EAAK9F,GAAK,EAAG,KAChDG,EAAOe,MAAMC,QAAQtB,EAAQG,GAAGG,MAAQN,EAAQG,GAAGG,UAAOD,KAC3DC,OAGC+E,EAAMC,EAAYnF,MACZ,OAARkF,EAAc,oCAEjBa,IAAmB5F,EAAnBgE,OAAAC,cAAA4B,GAAAD,EAAAE,EAAA1B,QAAAC,MAAAwB,GAAA,EAAyB,KAAdE,EAAcH,EAAAjE,MACpByD,EAAUzF,EAAOoG,EAAKtF,QACrB2E,IACJA,KACAzF,EAAOoG,EAAKtF,QAAU2E,GAEnBA,EAAQY,QAAQD,EAAKE,UAAY,GACpCb,EAAQH,KAAKc,EAAKE,kGAGd,KAEFb,EAAUzF,EAAOoF,MAChBK,EAEE,oCACNc,IAAuBlG,EAAvBgE,OAAAC,cAAAkC,GAAAD,EAAAE,EAAAhC,QAAAC,MAAA8B,GAAA,EAA6B,KAAlBF,EAAkBC,EAAAvE,MACxByD,EAAQY,QAAQC,GAAY,GAC/Bb,EAAQH,KAAKgB,4FAJftG,EAAOoF,GAAO/E,IAWO,mBAAbkC,GACVA,EAAS,KAAMvC,cFlIb0G,mCAUOnB,EAAWC,EAAQ1D,uGACxBA,IACNa,OAAOC,iBAAPC,uBAAAT,IAQCU,SAAWd,MAAO,aAIduD,UAAYA,GAAa,IAAIxC,mBAC7BjB,IACJyD,EAAUoB,aAAc,KAIpBnB,OACJA,GACA,IAAIP,aACHQ,QAASrD,EAAKmD,UAAUE,QACxBmB,0BAA0B,MAOvBC,UAAY,MAMZC,2BAA4B,IAM5BC,uBAAoB3G,IAMpB4G,oBAAiB5G,IAQjB6G,kBAAmB,IAOnBC,eAAgB,IAQhBC,eAAY/G,IAQZgH,aAAe,IAOfC,OAAS,OAMTC,OAAS,IAMTC,cAAWnH,uBA7GQyB,qEA8HbG,eACG5B,IAAV4B,EACIpB,KAAKwG,eAERI,MAAMxF,IAAUyF,OAAOzF,GAAS,SAC/BoF,aAAeK,OAAOzF,IAErBpB,uCAYCoB,UACHA,GAGgB,mBAAVA,SACL+E,kBAAoB/E,GAEnBpB,MALCA,KAAKmG,qDAeH/E,UACLA,GACgB,WAAjB0F,QAAO1F,UACLgF,eAAiBhF,GAEhBpB,MAJYA,KAAKoG,mDAqBbhF,eACG5B,IAAV4B,EAA4BpB,KAAKqG,uBAChCA,mBAAqBjF,EACnBpB,6CASOoB,UACVwF,MAAMC,OAAOzF,IAAgBpB,KAAKiG,gBACjCA,UAAY7E,EACVpB,uDAaiBoB,eACV5B,IAAV4B,EAA4BpB,KAAKkG,gCAChCA,4BAA8B9E,EAC5BpB,uCAeCoB,eACM5B,IAAV4B,EAA4BpB,KAAKsG,oBAChCA,gBAAkBlF,EAChBpB,uCAeCoB,eACM5B,IAAV4B,EAA4BpB,KAAKuG,gBAChCA,UAAYnF,QAAgB5B,EAC1BQ,mCAcH2B,SAEoB,mBAAbA,SACLwE,kBAAoBxE,QAErB+E,OAAS,EACV1G,KAAKwG,aAAe,SAClBC,OAASpE,MAAMrC,KAAKwG,eAAiBO,EAAAA,EAAW,KAAO/G,KAAKwG,oBAE7DQ,SAAS,IAAIC,WAAWjH,KAAKiG,UAAW,IACtCjG,2CAYM0B,EAAOoC,EAAM/C,MACtB+C,SACE4C,OAAS,GAGX1G,KAAKmG,kBAAmB,KACvBe,GAAQxF,EAAO1B,KAAK2G,UACpB3G,KAAKqG,mBACRa,EAAKxC,KAAKZ,GACVoD,EAAKxC,KAAK3D,SAENoF,kBAAkBgB,MAAMnH,KAAMkH,qCAW5BnG,cACFwB,EAAOvC,KAAKkB,YACZkB,EAAIpC,KAAKyG,OACXW,EAAarG,aAAgBkG,WAAalG,EAAO,IAAIkG,WACnDI,EAAc,IAAIhD,YAAYrE,KAAK4E,QACzCyC,EAAYrB,0BACVhG,KAAKkG,4BAA6B9D,GAA4B,IAAtBgF,EAAWE,WAEjD7E,EAAMzC,KAAKsG,cACZtG,KAAK2E,UAAU4C,gBACfF,EACAG,kBAAkBC,gBAClBjI,OACAA,EACA4H,GAEApH,KAAK2E,UAAU+C,aAAaL,OAAa7H,EAAW4H,MACnDpH,KAAKoG,eAAgB,KACpBuB,EAAcC,SAASC,eAAe7H,KAAKoG,gBAC3CuB,IACHlF,GAAO,IAAMkF,OAGTG,EAAS9H,KAAKuG,UAAY9D,EAAIsF,QAAQ,mBAAoB/H,KAAKuG,WAAa9D,EAE5EE,EADa3C,KAAKsC,SACDwF,GACrBlF,GAAG,aAAc,SAAAC,GACbN,GAAQA,EAAKO,kBAChBP,EAAKQ,QACHC,QAAO,GACPP,IAAIA,GAAK,GACXI,EAAQI,iBAAiBC,YAAYC,UAAWZ,EAAKa,wBACrDP,EAAQI,iBAAiBC,YAAYG,cAAed,EAAKe,wBAG1DV,GAAG,OAAQ,SAAAtC,OACP0H,EAAY3H,eAAeC,WACbd,IAAdwI,IACHlI,OAAIC,MAAM,2BAA4B+H,GACjC1F,QAMA6F,EAAUC,EAAK7B,iBACf8B,EAAarH,gBAAgBR,EAAM8G,GACnCvG,EAAeP,GAAQA,EAAKb,KAAOa,EAAKb,KAAKoB,aAAe,aAE5CrB,IAAlB0I,EAAKvB,UAA0BsB,EAAS,IAC3CC,EAAKvB,SAAWqB,EAGZZ,EAAWpG,IAAM,EAAG,KACjBA,EAAMN,kBAAkBJ,GAC1BU,EAAM,IACToG,EAAa,IAAIH,WAAWjG,EAAKoG,EAAWE,SAG1CW,GACHC,EAAKE,mBAAc5I,EAAW2I,EAAa,EAAGf,QAEpChF,IACX8F,EAAKvB,SAAWuB,EAAKvB,SAAS0B,OAAOL,OAIlCG,EAAa,GAAM/F,GAAKgF,EAAWE,OAAS,KAC3ClF,MACCvB,EAAe,EAAG,KAGpB,IAAIyH,EAAUH,EACdG,EAAUzH,EACVyH,GAAWlB,EAAWpG,IAEtBkH,EAAKlB,SAASI,EAAWmB,WAAWD,IAErClG,EAAE2B,SAAS,SAACrC,EAAO8G,IAEhB9G,GACD8G,GACAA,EAAWC,UAAU,SAAAC,eAAalJ,IAAPkJ,KAAqB,IAMhDhH,EAAQ,IAAIE,MACX,6EAGGF,GACJ8G,EACEG,IAAI,SAASC,UACNvI,eAAeuI,SAEtBC,QAAQ,SAAAC,GACRZ,EAAKvB,SAAWuB,EAAKvB,SAAS0B,OAAOS,KAGxCZ,EAAKE,cAAwB,OAAV1G,EAAiBA,OAAQlC,GAAW,WAIzD0I,EAAKlB,SAASI,EAAWmB,WAAWJ,SAE1BF,GACXC,EAAKE,mBAAc5I,GAAW,QApE7B0I,EAAKE,kBAuEPxF,GAAG,QAAS,SAAAlB,GACZ5B,OAAI4B,MAAM,mCAAoCoG,EAAQpG,GACtDwG,EAAKE,cAAc,IAAIxG,MAAJ,6BAAAyG,OAAuCP,EAAvC,MAAAO,OAAkD3G,OAEnEU,GAAKgF,EAAWE,OAAS,EAC5BlF,EAAEmB,MAAMZ,EAAIa,IAAK,MAEjBb,EAAIa,eGpaDuF,kCAMOC,2BACXjH,OAAOC,iBAAiBhC,MAQvBkC,SAAWd,MAAO,gBAOd6H,SAAWD,OAMX7C,uBAAoB3G,OAMpBgH,aAAeO,EAAAA,2DAYT3F,WACG5B,IAAV4B,SACIpB,KAAKwG,iBAET0C,EAAIrC,OAAOzF,UACVwF,MAAMxF,IAAU8H,EAAI,SACnB1C,aAAe0C,GAEdlJ,uDAWA,IAAIqB,QAAQ,SAACC,EAASC,GAC5BC,EAAKC,KAAK,SAACC,EAAOvC,GACbuC,EACHH,EAAOG,GAEPJ,EAAQnC,oCAgBPwC,cAEoB,mBAAbA,SACLwE,kBAAoBxE,OAEpBS,EAAIC,MAAMrC,KAAKwG,0BAChByC,SAASJ,QAAQ,SAAAM,GAErB/G,EAAEmB,MAAM4F,EAAO1H,KAAK2H,KAAKD,MAE1B/G,EAAE2B,SAAS,SAACrC,EAAOvC,GACd+I,EAAK/B,mBACR+B,EAAK/B,kBAAkBkD,KAAKnB,EAAMxG,EAAOvC,KAGpCa,sCAWCoB,UACHA,GAGgB,mBAAVA,SACL+E,kBAAoB/E,GAEnBpB,MALCA,KAAKmG","file":"lib/solarnetwork-datum-loader.es.min.js.map","sourcesContent":["import { queue } from \"d3-queue\";\nimport { HttpHeaders, Logger as log, NodeDatumUrlHelper } from \"solarnetwork-api-core\";\n\nimport JsonClientSupport from \"./jsonClientSupport\";\n\n/**\n * @typedef {Object} DatumRange\n * @property {string} timeZone the local time zone of the node\n * @property {number} startDateMillis the start of the time range, in milliseconds since the epoch\n * @property {number} endDateMillis the end of the time range, in milliseconds since the epoch\n * @property {Date} sDate the start of the time range\n * @property {Date} eDate the end of the time range\n */\n\n/**\n * The data callback function.\n *\n * @callback DatumRangeFinder~dataCallback\n * @param {Error} [error] an error if a failure occurred\n * @param {DatumRange} data the result data\n */\n\n/**\n * Class to find the available datum date range for a set of node datum URL helpers.\n *\n * This is useful when generating reports or charts for a set of SolarNode datum streams,\n * so the overall start/end dates can be determined before requesting the actual data.\n * It returns an object starting and ending date related properties, for example:\n *\n * ```\n * {\n *   \"timeZone\":        \"Pacific/Auckland\",\n *   \"sDate\":           Date(1248668709972),\n *   \"startDate\":       \"2009-07-27 16:25\",\n *   \"startDateMillis\": 1248668709972,\n *   \"eDate\":           Date(1379824746781),\n *   \"endDate\":         \"2013-09-22 16:39\",\n *   \"endDateMillis\":   1379824746781\n * }\n * ```\n * @extends {JsonClientSupport}\n * @example\n * // the simple case, for just one SolarNode\n * const urlHelper = new NodeDatumUrlHelper();\n * urlHelper.publicQuery = true;\n * urlHelper.nodeId = 123;\n * urlHelper.sourceIds = ['a', 'b'];\n * const range = await new DatumRangeFinder(urlHelper).fetch();\n *\n * @example\n * // more complex case, for multiple SolarNode / source ID combinations\n * const urlHelper2 = new NodeDatumUrlHelper();\n * urlHelper2.publicQuery = true;\n * urlHelper2.nodeId = 234;\n * urlHelper2.sourceId = 'c';\n * const range2 = await new DatumRangeFinder([urlHelper, urlHelper2]).fetch();\n *\n * @example\n * // with authentication; note the authentication must be valid for all SolarNodes!\n * const auth = new AuthorizationV2Builder('my-token');\n * auth.saveSigningKey('secret');\n * urlHelper.publicQuery = false;\n * urlHelper2.publicQuery = false;\n * const range3 = await new DatumRangeFinder([urlHelper, urlHelper2], auth).fetch();\n */\nclass DatumRangeFinder extends JsonClientSupport {\n\t/**\n\t * Constructor.\n\t *\n\t * @param {NodeDatumUrlHelper|NodeDatumUrlHelper[]} urlHelpers the helper(s) to find the avaialble data range for\n\t * @param {AuthorizationV2Builder} [authBuilder] the auth builder to authenticate requests with; if not provided\n\t *                                               then only public data can be queried; when provided a pre-signed\n\t *                                               key must be available\n\t */\n\tconstructor(urlHelpers, authBuilder) {\n\t\tsuper(authBuilder);\n\t\tObject.defineProperties(this, {\n\t\t\t/**\n\t\t\t * The class version.\n\t\t\t *\n\t\t\t * @memberof DatumRangeFinder\n\t\t\t * @readonly\n\t\t\t * @type {string}\n\t\t\t */\n\t\t\tversion: { value: \"1.0.0\" }\n\t\t});\n\n\t\t/**\n\t\t * @type {NodeDatumUrlHelper[]}\n\t\t * @private\n\t\t */\n\t\tthis._helpers = Array.isArray(urlHelpers)\n\t\t\t? urlHelpers\n\t\t\t: urlHelpers\n\t\t\t? [urlHelpers]\n\t\t\t: [new NodeDatumUrlHelper()];\n\t}\n\n\t/**\n\t * Asynchronously find the available datum range using a callback.\n\t *\n\t * @param {DatumRangeFinder~dataCallback} callback the callback function to invoke\n\t * @returns {void}\n\t */\n\tload(callback) {\n\t\tconst q = queue();\n\t\tconst jsonClient = this.client();\n\t\tconst auth = this.authBuilder;\n\t\tfor (const urlHelper of this._helpers) {\n\t\t\tconst url = urlHelper.reportableIntervalUrl();\n\t\t\tconst req = jsonClient(url).on(\"beforesend\", request => {\n\t\t\t\tif (auth && auth.signingKeyValid) {\n\t\t\t\t\tauth.reset()\n\t\t\t\t\t\t.snDate(true)\n\t\t\t\t\t\t.url(url, true);\n\t\t\t\t\trequest.setRequestHeader(HttpHeaders.X_SN_DATE, auth.requestDateHeaderValue);\n\t\t\t\t\trequest.setRequestHeader(HttpHeaders.AUTHORIZATION, auth.buildWithSavedKey());\n\t\t\t\t}\n\t\t\t});\n\t\t\tq.defer(req.get, null);\n\t\t}\n\t\tq.awaitAll((error, results) => {\n\t\t\tif (error) {\n\t\t\t\tlog.error(\"Error requesting available data range: %s\", error);\n\t\t\t\tif (typeof callback === \"function\") {\n\t\t\t\t\tcallback(error);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tvar intervalObj = extractReportableInterval(results);\n\t\t\tif (intervalObj.startDateMillis !== undefined) {\n\t\t\t\tintervalObj.sDate = new Date(intervalObj.startDateMillis);\n\t\t\t}\n\t\t\tif (intervalObj.endDateMillis !== undefined) {\n\t\t\t\tintervalObj.eDate = new Date(intervalObj.endDateMillis);\n\t\t\t}\n\n\t\t\tif (typeof callback === \"function\") {\n\t\t\t\tcallback(null, intervalObj);\n\t\t\t}\n\t\t});\n\t}\n}\n\nfunction extractReportableInterval(results) {\n\tvar result,\n\t\ti = 0,\n\t\trepInterval;\n\tfor (i = 0; i < results.length; i += 1) {\n\t\trepInterval = results[i];\n\t\tif (repInterval.data === undefined || repInterval.data.endDate === undefined) {\n\t\t\tlog.debug(\n\t\t\t\t\"No data available for %s sources %s\",\n\t\t\t\tthis._helpers[i].nodeId,\n\t\t\t\tthis._helpers[i].sourceIds.join(\",\")\n\t\t\t);\n\t\t\tcontinue;\n\t\t}\n\t\trepInterval = repInterval.data;\n\t\tif (result === undefined) {\n\t\t\tresult = repInterval;\n\t\t} else {\n\t\t\t// merge start/end dates\n\t\t\t// note we don't copy the time zone... this breaks when the tz are different!\n\t\t\tif (repInterval.endDateMillis > result.endDateMillis) {\n\t\t\t\tresult.endDateMillis = repInterval.endDateMillis;\n\t\t\t\tresult.endDate = repInterval.endDate;\n\t\t\t}\n\t\t\tif (repInterval.startDateMillis < result.startDateMillis) {\n\t\t\t\tresult.startDateMillis = repInterval.startDateMillis;\n\t\t\t\tresult.startDate = repInterval.startDate;\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n}\n\nexport default DatumRangeFinder;\n","import {\n\tDatumFilter,\n\tDatumReadingTypes,\n\tHttpHeaders,\n\tLogger as log,\n\tNodeDatumUrlHelper,\n\tPagination,\n\turlQuery\n} from \"solarnetwork-api-core\";\n\nimport { queue } from \"d3-queue\";\nimport JsonClientSupport from \"./jsonClientSupport\";\n\n/**\n * @typedef {Object} Datum\n * @property {string} created the datum date\n * @property {string} sourceId the control ID\n */\n\n/**\n * The data callback function.\n *\n * @callback DatumLoader~dataCallback\n * @param {Error} [error] an error if a failure occurred\n * @param {Datum[]} data the result data\n * @param {boolean} [done] in incremental mode, will be `true` when invoked on the *last* page of data\n * @param {Pagination} [page] in incremental mode, the page associated with the data\n */\n\n/**\n * Load data for a set of source IDs, date range, and aggregate level using either the `listDatumUrl()`\n * or `datumReadingUrl()` URLs of `NodeDatumUrlHelperMixin` (the `/datum/list` or `/datum/reading`\n * endpoints).\n *\n * This object is designed to be used once per query. After creating the object and configuring an\n * asynchronous callback function with {@link DatumLoader#callback}, call {@link DatumLoader#load}\n * to start loading the data. The callback function will be called once all data has been loaded. The\n * callback function can also be passed as an argument to the {@link DatumLoader#load} method directly.\n *\n * @implements {Loader}\n * @extends {JsonClientSupport}\n * @example\n * const filter = new DatumFilter();\n * filter.nodeId = 123;\n * // configure other filter settings here...\n *\n * const urlHelper = new NodeDatumUrlHelper();\n *\n * new DatumLoader(urlHelper, filter).load((error, results) => {\n *   // results is an array of Datum objects\n * });\n * @version 1.2.0\n */\nclass DatumLoader extends JsonClientSupport {\n\t/**\n\t * Constructor.\n\t *\n\t * @param {NodeDatumUrlHelperMixin} urlHelper a URL helper for accessing node datum via SolarQuery\n\t * @param {DatumFilter} filter the filter parameters to use\n\t * @param {AuthorizationV2Builder} [authBuilder] the auth builder to authenticate requests with; if not provided\n\t *                                               then only public data can be queried; when provided a pre-signed\n\t *                                               key must be available\n\t */\n\tconstructor(urlHelper, filter, authBuilder) {\n\t\tsuper(authBuilder);\n\t\tObject.defineProperties(this, {\n\t\t\t/**\n\t\t\t * The class version.\n\t\t\t *\n\t\t\t * @memberof DatumLoader\n\t\t\t * @readonly\n\t\t\t * @type {string}\n\t\t\t */\n\t\t\tversion: { value: \"1.2.0\" }\n\t\t});\n\n\t\t/** @type {NodeDatumUrlHelper} */\n\t\tthis.urlHelper = urlHelper || new NodeDatumUrlHelper();\n\t\tif (!authBuilder) {\n\t\t\turlHelper.publicQuery = true;\n\t\t}\n\n\t\t/** @type {DatumFilter} */\n\t\tthis.filter =\n\t\t\tfilter ||\n\t\t\tnew DatumFilter({\n\t\t\t\tnodeIds: this.urlHelper.nodeIds,\n\t\t\t\twithoutTotalResultsCount: true\n\t\t\t});\n\n\t\t/**\n\t\t * @type {number}\n\t\t * @private\n\t\t */\n\t\tthis._pageSize = 1000;\n\n\t\t/**\n\t\t * @type {boolean}\n\t\t * @private\n\t\t */\n\t\tthis._includeTotalResultsCount = false;\n\n\t\t/**\n\t\t * @type {DatumLoader~dataCallback}\n\t\t * @private\n\t\t */\n\t\tthis._finishedCallback = undefined;\n\n\t\t/**\n\t\t * @type {object}\n\t\t * @private\n\t\t */\n\t\tthis._urlParameters = undefined;\n\n\t\t/**\n\t\t * When `true` then call the callback function for every page of data as it becomes available.\n\t\t * Otherwise the callback function will be invoked only after all data has been loaded.\n\t\t * @type {boolean}\n\t\t * @private\n\t\t */\n\t\tthis._incrementalMode = false;\n\n\t\t/**\n\t\t * When `true` then invoke the `/datum/reading` endpoint to load data, otherwise use `/datum/list`.\n\t\t * @type {boolean}\n\t\t * @private\n\t\t */\n\t\tthis._readingsMode = false;\n\n\t\t/**\n\t\t * An optional proxy URL to use instead of the host returned by the configured `NodeDatumUrlHelperMixin`.\n\t\t * This should be configured as an absolute URL to the proxy target, e.g. `https://query.solarnetwork.net/1m`.\n\t\t * @type {string}\n\t\t * @private\n\t\t */\n\t\tthis._proxyUrl = undefined;\n\n\t\t/**\n\t\t * When > 0 then make one request that includes the total result count and first page of\n\t\t * results, followed by parallel requests for the remaining pages.\n\t\t * @type {number}\n\t\t * @private\n\t\t */\n\t\tthis._concurrency = 0;\n\n\t\t/**\n\t\t * A queue to use for parallel mode, when `concurrency` configured > 0.\n\t\t * @type {queue}\n\t\t * @private\n\t\t */\n\t\tthis._queue = null;\n\n\t\t/**\n\t\t * @type {number}\n\t\t * @private\n\t\t */\n\t\tthis._state = 0;\n\n\t\t/**\n\t\t * @type {Datum[]}\n\t\t * @private\n\t\t */\n\t\tthis._results = undefined;\n\t}\n\n\t/**\n\t * Get or set the concurrency limit to use for parallel requests.\n\t *\n\t * By default requests are not made in parallel (this property is configured as `0`). Change\n\t * to a positive number to enable parallel query mode.\n\t *\n\t * When parallel mode is enabled the loader will make one request that includes\n\t * the total result count and first page of results, followed by parallel requests for any remaining pages\n\t * based on that total result count and configured page size.\n\t *\n\t * @param {number} [value] the concurrency level to use, or `Infinity` for no limit\n\t * @returns {number|DatumLoader} when used as a getter, the current concurrency value, otherwise this object\n\t * @since 1.1.0\n\t */\n\tconcurrency(value) {\n\t\tif (value === undefined) {\n\t\t\treturn this._concurrency;\n\t\t}\n\t\tif (!isNaN(value) && Number(value) > 0) {\n\t\t\tthis._concurrency = Number(value);\n\t\t}\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set the callback function, invoked after all data has been loaded. The callback\n\t * function will be passed two arguments: an error and the results. In incremental mode,\n\t * the callback will also be passed a boolean that will be `true` on that last page of data,\n\t * and a `Pagination` that details which page the callback represents.\n\t *\n\t * @param {DatumLoader~dataCallback} [value] the callback function to use\n\t * @returns  {DatumLoader~dataCallback|DatumLoader} when used as a getter, the current callback function, otherwise this object\n\t */\n\tcallback(value) {\n\t\tif (!value) {\n\t\t\treturn this._finishedCallback;\n\t\t}\n\t\tif (typeof value === \"function\") {\n\t\t\tthis._finishedCallback = value;\n\t\t}\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set additional URL parameters. The parameters are set as object properties.\n\t * If a property value is an array, multiple parameters for that property will be added.\n\t *\n\t * @param {object} [value] the URL parameters to include with the JSON request\n\t * @returns {object|DatumLoader} when used as a getter, the URL parameters, otherwise this object\n\t */\n\tparameters(value) {\n\t\tif (!value) return this._urlParameters;\n\t\tif (typeof value === \"object\") {\n\t\t\tthis._urlParameters = value;\n\t\t}\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set _incremental mode_ for loading the data.\n\t *\n\t * When incremental mode is enabled (set to `true`) then the callback function will be invoked\n\t * for _each result page_ that is loaded. The function will be passed a second `boolean` argument\n\t * that will be set to `true` only on the last page of result data, and a third Pagination`\n\t * object argument that details the starting offset of the page.\n\t *\n\t * When incremental mode is disabled (set to `false`, the default) then all result pages are\n\t * combined into a single array and the callback will be invoked just once.\n\t *\n\t * @param {boolean} [value] the incremental mode to set\n\t * @returns {boolean|DatumLoader} when used a a getter, the incremental mode; otherwise this object\n\t */\n\tincremental(value) {\n\t\tif (value === undefined) return this._incrementalMode;\n\t\tthis._incrementalMode = !!value;\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set the result pagination size.\n\t *\n\t * @param {number} [value] the pagination size to set; defaults to `1000`\n\t * @returns {number|DatumLoader} when used as a getter, the pagination size; otherwise this object\n\t */\n\tpaginationSize(value) {\n\t\tif (isNaN(Number(value))) return this._pageSize;\n\t\tthis._pageSize = value;\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set the flag for requesting the total results count.\n\t *\n\t * By default the datum loader will _not_ request the overal total result count when querying\n\t * for data, as this speeds up queries. By setting this to `true` the total result count will\n\t * be requested on the _first_ query page.\n\t *\n\t * @param {boolean} [value] the flag to include total results count\n\t * @returns {boolean|DatumLoader} when used a a getter, the total results count inclusion mode; otherwise this object\n\t */\n\tincludeTotalResultsCount(value) {\n\t\tif (value === undefined) return this._includeTotalResultsCount;\n\t\tthis._includeTotalResultsCount = !!value;\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set _readings mode_ for loading the data.\n\t *\n\t * When readings mode is enabled (set to `true`) then the `/datum/reading` endpoint will be invoked\n\t * to load data.\n\t *\n\t * When readings mode is disabled (set to `false`, the default) then the `/datum/list` endpoint will\n\t * be invoked to load data.\n\t *\n\t * @param {boolean} [value] the readings mode to set\n\t * @returns {boolean|DatumLoader} when used a a getter, the readings mode; otherwise this object\n\t */\n\treadings(value) {\n\t\tif (value === undefined) return this._readingsMode;\n\t\tthis._readingsMode = !!value;\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set the URL to a proxy to use for loading the data.\n\t *\n\t * This can be configured as an absolute URL to the proxy server to use instead of making requests\n\t * directly to the URL returned by the configured `NodeDatumUrlHelperMixin`. For example:\n\t *\n\t * * https://query.solarnetwork.net\n\t * * https://query.solarnetwork.net/1m\n\t *\n\t * @param {string} [value] the proxy URL to set, or `null` or an empty string to not use any proxy\n\t * @returns {string|DatumLoader} when used a a getter, the readings mode; otherwise this object\n\t */\n\tproxyUrl(value) {\n\t\tif (value === undefined) return this._proxyUrl;\n\t\tthis._proxyUrl = value ? value : undefined;\n\t\treturn this;\n\t}\n\n\t/**\n\t * Initiate loading the data.\n\t *\n\t * As an alternative to configuring the callback function via the {@link DatumLoader#callback}\n\t * method,a callback function can be passed as an argument to this function. That allows this\n\t * function to be passed to things like `queue.defer`, for example.\n\t *\n\t * @param {DatumLoader~dataCallback} [callback] a callback function to use; either this argument must be provided\n\t *                              or the function must have already been configured via {@link DatumLoader#callback}\n\t * @returns {DatumLoader} this object\n\t */\n\tload(callback) {\n\t\t// to support queue use, allow callback to be passed directly to this function\n\t\tif (typeof callback === \"function\") {\n\t\t\tthis._finishedCallback = callback;\n\t\t}\n\t\tthis._state = 1;\n\t\tif (this._concurrency > 0) {\n\t\t\tthis._queue = queue(this._concurrency === Infinity ? null : this._concurrency);\n\t\t}\n\t\tthis.loadData(new Pagination(this._pageSize, 0));\n\t\treturn this;\n\t}\n\n\t/**\n\t * Invoke the configured callback function.\n\t *\n\t * @param {Error} [error] an optional  error\n\t * @param {boolean} done `true` if there is no more data to load\n\t * @param {Pagination} [page] the incremental mode page\n\t * @returns {void}\n\t * @private\n\t */\n\thandleResults(error, done, page) {\n\t\tif (done) {\n\t\t\tthis._state = 2; // done\n\t\t}\n\n\t\tif (this._finishedCallback) {\n\t\t\tlet args = [error, this._results];\n\t\t\tif (this._incrementalMode) {\n\t\t\t\targs.push(done);\n\t\t\t\targs.push(page);\n\t\t\t}\n\t\t\tthis._finishedCallback.apply(this, args);\n\t\t}\n\t}\n\n\t/**\n\t * Load a single page of data, starting at a specific offset.\n\t *\n\t * @param {Pagination} [page] the page to load\n\t * @returns {void}\n\t * @private\n\t */\n\tloadData(page) {\n\t\tconst auth = this.authBuilder;\n\t\tconst q = this._queue;\n\t\tlet pagination = page instanceof Pagination ? page : new Pagination();\n\t\tconst queryFilter = new DatumFilter(this.filter);\n\t\tqueryFilter.withoutTotalResultsCount =\n\t\t\t(this._includeTotalResultsCount || q) && pagination.offset === 0 ? false : true;\n\n\t\tlet url = this._readingsMode\n\t\t\t? this.urlHelper.datumReadingUrl(\n\t\t\t\t\tqueryFilter,\n\t\t\t\t\tDatumReadingTypes.Difference,\n\t\t\t\t\tundefined,\n\t\t\t\t\tundefined,\n\t\t\t\t\tpagination\n\t\t\t  )\n\t\t\t: this.urlHelper.listDatumUrl(queryFilter, undefined, pagination);\n\t\tif (this._urlParameters) {\n\t\t\tlet queryParams = urlQuery.urlQueryEncode(this._urlParameters);\n\t\t\tif (queryParams) {\n\t\t\t\turl += \"&\" + queryParams;\n\t\t\t}\n\t\t}\n\t\tconst reqUrl = this._proxyUrl ? url.replace(/^[^:]+:\\/\\/[^/]+/, this._proxyUrl) : url;\n\t\tconst jsonClient = this.client();\n\t\tconst req = jsonClient(reqUrl)\n\t\t\t.on(\"beforesend\", request => {\n\t\t\t\tif (auth && auth.signingKeyValid) {\n\t\t\t\t\tauth.reset()\n\t\t\t\t\t\t.snDate(true)\n\t\t\t\t\t\t.url(url, true);\n\t\t\t\t\trequest.setRequestHeader(HttpHeaders.X_SN_DATE, auth.requestDateHeaderValue);\n\t\t\t\t\trequest.setRequestHeader(HttpHeaders.AUTHORIZATION, auth.buildWithSavedKey());\n\t\t\t\t}\n\t\t\t})\n\t\t\t.on(\"load\", json => {\n\t\t\t\tlet dataArray = datumExtractor(json);\n\t\t\t\tif (dataArray === undefined) {\n\t\t\t\t\tlog.debug(\"No data available for %s\", reqUrl);\n\t\t\t\t\tif (!q) {\n\t\t\t\t\t\tthis.handleResults();\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tconst incMode = this._incrementalMode;\n\t\t\t\tconst nextOffset = offsetExtractor(json, pagination);\n\t\t\t\tconst totalResults = json && json.data ? json.data.totalResults : null;\n\n\t\t\t\tif (this._results === undefined || incMode) {\n\t\t\t\t\tthis._results = dataArray;\n\n\t\t\t\t\t// discover page size, if pagination does not already have one\n\t\t\t\t\tif (pagination.max < 1) {\n\t\t\t\t\t\tconst max = pageSizeExtractor(json);\n\t\t\t\t\t\tif (max > 0) {\n\t\t\t\t\t\t\tpagination = new Pagination(max, pagination.offset);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (incMode) {\n\t\t\t\t\t\tthis.handleResults(undefined, nextOffset < 1, pagination);\n\t\t\t\t\t}\n\t\t\t\t} else if (!q) {\n\t\t\t\t\tthis._results = this._results.concat(dataArray);\n\t\t\t\t}\n\n\t\t\t\t// see if we need to load more results\n\t\t\t\tif (nextOffset > 0 || (q && pagination.offset > 0)) {\n\t\t\t\t\tif (q) {\n\t\t\t\t\t\tif (totalResults > 0) {\n\t\t\t\t\t\t\t// parallel mode with first page results; queue all remaining pages\n\t\t\t\t\t\t\tfor (\n\t\t\t\t\t\t\t\tlet pOffset = nextOffset;\n\t\t\t\t\t\t\t\tpOffset < totalResults;\n\t\t\t\t\t\t\t\tpOffset += pagination.max\n\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\tthis.loadData(pagination.withOffset(pOffset));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tq.awaitAll((error, allResults) => {\n\t\t\t\t\t\t\t\tif (\n\t\t\t\t\t\t\t\t\t!error &&\n\t\t\t\t\t\t\t\t\tallResults &&\n\t\t\t\t\t\t\t\t\tallResults.findIndex(el => el === undefined) >= 0\n\t\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\t\t// some result is unexpectedly undefined; seen this under Node from\n\t\t\t\t\t\t\t\t\t// https://github.com/driverdan/node-XMLHttpRequest/issues/162\n\t\t\t\t\t\t\t\t\t// where the HTTP client lib is not reporting back an actual error value\n\t\t\t\t\t\t\t\t\t// when something happens like a response timeout\n\t\t\t\t\t\t\t\t\terror = new Error(\n\t\t\t\t\t\t\t\t\t\t\"One or more requests did not return a result, but no error was reported.\"\n\t\t\t\t\t\t\t\t\t);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif (!error) {\n\t\t\t\t\t\t\t\t\tallResults\n\t\t\t\t\t\t\t\t\t\t.map(function(qJson) {\n\t\t\t\t\t\t\t\t\t\t\treturn datumExtractor(qJson) || [];\n\t\t\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t\t\t\t.forEach(resultArray => {\n\t\t\t\t\t\t\t\t\t\t\tthis._results = this._results.concat(resultArray);\n\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tthis.handleResults(error !== null ? error : undefined, true);\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tthis.loadData(pagination.withOffset(nextOffset));\n\t\t\t\t\t}\n\t\t\t\t} else if (!incMode) {\n\t\t\t\t\tthis.handleResults(undefined, true);\n\t\t\t\t}\n\t\t\t})\n\t\t\t.on(\"error\", error => {\n\t\t\t\tlog.error(\"Error requesting data for %s: %s\", reqUrl, error);\n\t\t\t\tthis.handleResults(new Error(`Error requesting data for ${reqUrl}: ${error}`));\n\t\t\t});\n\t\tif (q && pagination.offset > 0) {\n\t\t\tq.defer(req.get, null);\n\t\t} else {\n\t\t\treq.get();\n\t\t}\n\t}\n}\n\n/**\n * Extract the datum list from the returned data.\n *\n * @param {object} json the JSON results to extract from\n * @returns {Datum[]} the extracted data\n * @private\n */\nfunction datumExtractor(json) {\n\tif (\n\t\t!json ||\n\t\tjson.success !== true ||\n\t\tjson.data === undefined ||\n\t\tArray.isArray(json.data.results) !== true\n\t) {\n\t\treturn undefined;\n\t}\n\treturn json.data.results;\n}\n\n/**\n * Extract the page size from the returned data.\n *\n * @param {object} json the JSON results to extract from\n * @returns {number} the extracted page size\n * @private\n */\nfunction pageSizeExtractor(json) {\n\tif (!(json && json.data)) {\n\t\treturn 0;\n\t}\n\tconst data = json.data;\n\treturn data.returnedResultCount + data.startingOffset < data.totalResults\n\t\t? data.returnedResultCount\n\t\t: 0;\n}\n\n/**\n * Extract the \"next\" offset to use based on the returned data.\n *\n * If `page` is supplied, then pagination will be based on `page.max` and will continue\n * until less than that many results are returned. If `page` is not supplied, then\n * pagination will be based on `data.returnedResultCount` and will continue until\n * `data.totalResults` has been returned.\n *\n * @param {object} json the JSON results to extract from\n * @param {Pagination} [page] the incremental mode page\n * @returns {number} the extracted offset, or `0` if no more pages to return\n * @private\n */\nfunction offsetExtractor(json, page) {\n\tif (!(json && json.data)) {\n\t\treturn 0;\n\t}\n\tconst data = json.data;\n\tif (page && page.max) {\n\t\t// don't bother with totalResults; just keep going unless returnedResultCount < page.max\n\t\treturn data.returnedResultCount < page.max ? 0 : data.startingOffset + page.max;\n\t}\n\treturn data.returnedResultCount + data.startingOffset < data.totalResults\n\t\t? data.returnedResultCount + data.startingOffset\n\t\t: 0;\n}\n\nexport default DatumLoader;\n","import { json } from \"d3-request\";\n\n/**\n * The data callback function.\n *\n * @callback JsonClientSupport~dataCallback\n * @param {Error} [error] an error if a failure occurred\n * @param {*} data the result data\n */\n\n/**\n * An abstract class with customizable JSON client support.\n *\n * @abstract\n */\nclass JsonClientSupport {\n\t/**\n\t * Constructor.\n\t *\n\t * @param {AuthorizationV2Builder} [authBuilder] the auth builder to authenticate requests with; if not provided\n\t *                                               then only public data can be queried\n\t */\n\tconstructor(authBuilder) {\n\t\t/**\n\t\t * An authorization builder to use to make authenticated HTTP requests.\n\t\t * @type {AuthorizationV2Builder}\n\t\t * @protected\n\t\t */\n\t\tthis.authBuilder = authBuilder;\n\n\t\t/**\n\t\t * The JSON client.\n\t\t * @private\n\t\t */\n\t\tthis.jsonClient = json;\n\t}\n\n\t/**\n\t * Get or set a JSON HTTP client function to use.\n\t *\n\t * The function must be compatible with `d3.json` and defaults to that. This provides a way\n\t * to integrate a different HTTP client if needed, for example a mock implementation in tests.\n\t *\n\t * @param {function} [value] the JSON client function, compatible with `d3.json`\n\t * @returns {function|DatumSourceFinder} when used as a getter, the JSON client function, otherwise this object\n\t */\n\tclient(value) {\n\t\tif (!value) return this.jsonClient;\n\t\tif (typeof value === \"function\") {\n\t\t\tthis.jsonClient = value;\n\t\t}\n\t\treturn this;\n\t}\n\n\t/**\n\t * Asynchronously load the data.\n\t *\n\t * This method calls {@link JsonClientSupport#load} to perform the actual work.\n\t *\n\t * @returns {Promise<*>} the result promise\n\t */\n\tfetch() {\n\t\treturn new Promise((resolve, reject) => {\n\t\t\tthis.load((error, results) => {\n\t\t\t\tif (error) {\n\t\t\t\t\treject(error);\n\t\t\t\t} else {\n\t\t\t\t\tresolve(results);\n\t\t\t\t}\n\t\t\t});\n\t\t});\n\t}\n\n\t/**\n\t * Asynchronously load the data using a callback.\n\t *\n\t * Extending classes must override this method to provide a useful implementation.\n\t *\n\t * @abstract\n\t * @param {JsonClientSupport~dataCallback} callback the callback function to invoke\n\t * @returns {void}\n\t */\n\tload(callback) {\n\t\tcallback(new Error(\"Abstract method must be implemented by subclass.\"));\n\t}\n}\n\nexport default JsonClientSupport;\n","import { queue } from \"d3-queue\";\nimport { DatumFilter, HttpHeaders, Logger as log, NodeDatumUrlHelper } from \"solarnetwork-api-core\";\n\nimport JsonClientSupport from \"./jsonClientSupport\";\n\n/**\n * The data callback function.\n *\n * @callback DatumSourceFinder~dataCallback\n * @param {Error} [error] an error if a failure occurred\n * @param {object} data the result data, with node ID keys and `string[]` values representing the source IDs\n */\n\n/**\n * Class to find the available datum sources for a set of node datum URL helpers.\n *\n * This helper is useful for finding what source IDs are avaialble for a set of nodes.\n * It returns an object with node ID properties with associated source ID array values,\n * for example:\n *\n * ```\n * { 123: [\"a\", \"b\", \"c\"] }\n * ```\n * @extends {JsonClientSupport}\n * @example\n * // the simple case, all available sources for just one SolarNode\n * const urlHelper = new NodeDatumUrlHelper();\n * urlHelper.publicQuery = true;\n * urlHelper.nodeId = 123;\n * const sources = await new DatumSourceFinder(urlHelper).fetch();\n *\n * @example\n * // find all sources matching a wildcard pattern within the past day\n * const filter = new DatumFilter();\n * filter.startDate = new Date(Date.now() - 24 * 60 * 60 * 1000);\n * filter.sourceId = '/power/**';\n * const sources2 = await new DatumSourceFinder(urlHelper).filter(filter).fetch();\n *\n * @example\n * // find all sources across multiple SolarNodes\n * const urlHelper2 = new NodeDatumUrlHelper();\n * urlHelper2.publicQuery = true;\n * urlHelper2.nodeId = 234;\n * const sources3 = await new DatumSourceFinder([urlHelper, urlHelper2]).fetch();\n */\nclass DatumSourceFinder extends JsonClientSupport {\n\t/**\n\t * Constructor.\n\t *\n\t * @param {NodeDatumUrlHelper|NodeDatumUrlHelper[]} urlHelpers the helper(s) to find the avaialble sources for\n\t * @param {AuthorizationV2Builder} [authBuilder] the auth builder to authenticate requests with; if not provided\n\t *                                               then only public data can be queried; when provided a pre-signed\n\t *                                               key must be available\n\t */\n\tconstructor(urlHelpers, authBuilder) {\n\t\tsuper(authBuilder);\n\t\tObject.defineProperties(this, {\n\t\t\t/**\n\t\t\t * The class version.\n\t\t\t *\n\t\t\t * @memberof DatumSourceFinder\n\t\t\t * @readonly\n\t\t\t * @type {string}\n\t\t\t */\n\t\t\tversion: { value: \"1.0.0\" }\n\t\t});\n\n\t\t/**\n\t\t * @type {NodeDatumUrlHelper[]}\n\t\t * @private\n\t\t */\n\t\tthis._helpers = Array.isArray(urlHelpers)\n\t\t\t? urlHelpers\n\t\t\t: urlHelpers\n\t\t\t? [urlHelpers]\n\t\t\t: [new NodeDatumUrlHelper()];\n\t}\n\n\t/**\n\t * Get or set a `DatumFilter` to limit the query with.\n\t *\n\t * The `startDate`, `endDate`, and `metadataFilter` properties can be used to limit the query scope.\n\t *\n\t * @param {DatumFilter} [value] the datum filter to use\n\t * @returns {function|DatumFilter} when used as a getter, the filter, otherwise this object\n\t */\n\tfilter(value) {\n\t\tif (!value) return this.datumFilter;\n\t\tif (value instanceof DatumFilter) {\n\t\t\tthis.datumFilter = value;\n\t\t}\n\t\treturn this;\n\t}\n\n\t/**\n\t * Asynchronously find the available datum range using a callback.\n\t *\n\t * @param {DatumSourceFinder~dataCallback} callback the callback function to invoke\n\t * @returns {void}\n\t */\n\tload(callback) {\n\t\tconst q = queue();\n\t\tconst jsonClient = this.client();\n\t\tconst auth = this.authBuilder;\n\t\tconst requestKeys = [];\n\n\t\tfunction addRequest(key, url) {\n\t\t\trequestKeys.push(key);\n\t\t\tconst req = jsonClient(url).on(\"beforesend\", request => {\n\t\t\t\tif (auth && auth.signingKeyValid) {\n\t\t\t\t\tauth.reset()\n\t\t\t\t\t\t.snDate(true)\n\t\t\t\t\t\t.url(url, true);\n\t\t\t\t\trequest.setRequestHeader(HttpHeaders.X_SN_DATE, auth.requestDateHeaderValue);\n\t\t\t\t\trequest.setRequestHeader(HttpHeaders.AUTHORIZATION, auth.buildWithSavedKey());\n\t\t\t\t}\n\t\t\t});\n\t\t\tq.defer(req.get, null);\n\t\t}\n\t\tfor (const urlHelper of this._helpers) {\n\t\t\tconst filter = new DatumFilter(this.datumFilter);\n\t\t\tfilter.nodeIds = urlHelper.nodeIds;\n\t\t\tif (filter.metadataFilter || filter.nodeIds.length === 1) {\n\t\t\t\t// when metadata filter used, multiple node IDs allowed\n\t\t\t\taddRequest(\n\t\t\t\t\tthis.metadataFilter ? null : filter.nodeId,\n\t\t\t\t\turlHelper.availableSourcesUrl(filter)\n\t\t\t\t);\n\t\t\t} else {\n\t\t\t\t// no metadata filter, or multiple node IDs, so add one node ID at a time\n\t\t\t\tfor (const nodeId of filter.nodeIds) {\n\t\t\t\t\tconst oneFilter = new DatumFilter(filter);\n\t\t\t\t\toneFilter.nodeId = nodeId;\n\t\t\t\t\taddRequest(nodeId, urlHelper.availableSourcesUrl(oneFilter));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tq.awaitAll((error, results) => {\n\t\t\tif (error) {\n\t\t\t\tlog.error(\"Error requesting available sources: %s\", error);\n\t\t\t\tif (typeof callback === \"function\") {\n\t\t\t\t\tcallback(error);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tconst result = {};\n\n\t\t\tfor (let i = 0, len = results.length; i < len; i += 1) {\n\t\t\t\tconst data = Array.isArray(results[i].data) ? results[i].data : undefined;\n\t\t\t\tif (!data) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tconst key = requestKeys[i];\n\t\t\t\tif (key === null) {\n\t\t\t\t\t// result is array of nodeId/soruceId pairs, e.g. {nodeId:1, sourceId:\"foo\"}\n\t\t\t\t\tfor (const pair of data) {\n\t\t\t\t\t\tlet nodeIds = result[pair.nodeId];\n\t\t\t\t\t\tif (!nodeIds) {\n\t\t\t\t\t\t\tnodeIds = [];\n\t\t\t\t\t\t\tresult[pair.nodeId] = nodeIds;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (nodeIds.indexOf(pair.sourceId) < 0) {\n\t\t\t\t\t\t\tnodeIds.push(pair.sourceId);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\t// result is array of sourceIds\n\t\t\t\t\tlet nodeIds = result[key];\n\t\t\t\t\tif (!nodeIds) {\n\t\t\t\t\t\tresult[key] = data;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tfor (const sourceId of data) {\n\t\t\t\t\t\t\tif (nodeIds.indexOf(sourceId) < 0) {\n\t\t\t\t\t\t\t\tnodeIds.push(sourceId);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (typeof callback === \"function\") {\n\t\t\t\tcallback(null, result);\n\t\t\t}\n\t\t});\n\t}\n}\n\nexport default DatumSourceFinder;\n","import { queue } from \"d3-queue\";\n\n/**\n * Interface for classes that can be used to load data for {@link MultiLoader}.\n *\n * @interface Loader\n */\n\n/**\n * The loader callback function.\n *\n * @callback Loader~dataCallback\n * @param {Error} [error] an error if a failure occurred\n * @param {Object} data the result data\n */\n\n/**\n * Load data asynchronously with a callback.\n *\n * @function\n * @name Loader#load\n * @param {Loader~dataCallback} callback the callback to invoke with the results\n * @returns {Loader} the loader object\n */\n\n/**\n * The data callback function.\n *\n * @callback MultiLoader~dataCallback\n * @param {Error} [error] an error if a failure occurred\n * @param {Object[]} data the result data from all loaders\n */\n\n/**\n * Load data from multiple {@link Loader} objects, invoking a callback function\n * after all data has been loaded. Call {@link MultiLoader#load} to start loading the data.\n *\n * The {@link DatumLoader} class conforms to the {@link Loader} interface, so can be used to\n * load arrays of {@link Datum} objects based on search criteria.\n *\n * @example\n * const filter1 = new DatumFilter();\n * filter1.nodeId = 123;\n * // configure other filter settings here...\n *\n * const filter2 = new DatumFilter();\n * filter2.nodeId = 234;\n * // configure other filter settings here\n *\n * const urlHelper = new NodeDatumUrlHelper();\n *\n * new MultiLoader([\n *   new DatumLoader(urlHelper, filter1),\n *   new DatumLoader(urlHelper, filter2),\n * ]).load((error, results) => {\n *   // results is a 2-element array of Datum arrays\n * });\n *\n * @version 1.1.0\n */\nclass MultiLoader {\n\t/**\n\t * Constructor.\n\t *\n\t * @param {Loader[]} loaders - array of loader objects\n\t */\n\tconstructor(loaders) {\n\t\tObject.defineProperties(this, {\n\t\t\t/**\n\t\t\t * The class version.\n\t\t\t *\n\t\t\t * @memberof MultiLoader\n\t\t\t * @readonly\n\t\t\t * @type {string}\n\t\t\t */\n\t\t\tversion: { value: \"1.1.0\" }\n\t\t});\n\n\t\t/**\n\t\t * @type {Loader[]}\n\t\t * @private\n\t\t */\n\t\tthis._loaders = loaders;\n\n\t\t/**\n\t\t * @type {MultiLoader~dataCallback}\n\t\t * @private\n\t\t */\n\t\tthis._finishedCallback = undefined;\n\n\t\t/**\n\t\t * @type {number}\n\t\t * @private\n\t\t */\n\t\tthis._concurrency = Infinity;\n\t}\n\n\t/**\n\t * Get or set the concurrency limit to use for requets.\n\t *\n\t * A default, infinite concurrency queue will be used by default.\n\t *\n\t * @param {number} [value] the concurrency level to use, or `Infinity` for no limit\n\t * @returns {number|MultiLoader} when used as a getter, the current concurrency value, otherwise this object\n\t * @since 1.1.0\n\t */\n\tconcurrency(value) {\n\t\tif (value === undefined) {\n\t\t\treturn this._concurrency;\n\t\t}\n\t\tvar n = Number(value);\n\t\tif (!isNaN(value) && n > 0) {\n\t\t\tthis._concurrency = n;\n\t\t}\n\t\treturn this;\n\t}\n\n\t/**\n\t * Asynchronously load the data.\n\t *\n\t * This method calls {@link MultiLoader#load} to perform the actual work.\n\t *\n\t * @returns {Promise<Object[]>} the result promise\n\t */\n\tfetch() {\n\t\treturn new Promise((resolve, reject) => {\n\t\t\tthis.load((error, results) => {\n\t\t\t\tif (error) {\n\t\t\t\t\treject(error);\n\t\t\t\t} else {\n\t\t\t\t\tresolve(results);\n\t\t\t\t}\n\t\t\t});\n\t\t});\n\t}\n\n\t/**\n\t * Initiate loading the data. This will call {@link Loader#load} on each\n\t * supplied loader, in parallel. As an alternative to configuring the callback function via\n\t * the {@link MultiLoader#callback} method, a callback function can be passed as an argument\n\t * to this function. This allows this function to be passed to `queue.defer`, for example.\n\t *\n\t * @param {MultiLoader~dataCallback} [callback] a callback function to use; either this argument must be provided\n\t *                              or the function must have already been configured via  {@link MultiLoader#callback}\n\t * @returns {MultiLoader} this object\n\t */\n\tload(callback) {\n\t\t// to support queue use, allow callback to be passed directly to this function\n\t\tif (typeof callback === \"function\") {\n\t\t\tthis._finishedCallback = callback;\n\t\t}\n\t\tconst q = queue(this._concurrency);\n\t\tthis._loaders.forEach(loader => {\n\t\t\t// queue.defer will invoke the callback with a `null` `this` object, so `e.load.bind` here\n\t\t\tq.defer(loader.load.bind(loader));\n\t\t});\n\t\tq.awaitAll((error, results) => {\n\t\t\tif (this._finishedCallback) {\n\t\t\t\tthis._finishedCallback.call(this, error, results);\n\t\t\t}\n\t\t});\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get or set the callback function, invoked after all data has been loaded. The callback\n\t * function will be passed two arguments: an error and the results as an array of results\n\t * from each configured {@link Loader}.\n\t *\n\t * @param {MultiLoader~dataCallback} [value] the callback function to use\n\t * @returns  {MultiLoader~dataCallback|MultiLoader} when used as a getter, the current callback function, otherwise this object\n\t */\n\tcallback(value) {\n\t\tif (!value) {\n\t\t\treturn this._finishedCallback;\n\t\t}\n\t\tif (typeof value === \"function\") {\n\t\t\tthis._finishedCallback = value;\n\t\t}\n\t\treturn this;\n\t}\n}\n\nexport default MultiLoader;\n"]}